{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UyvrKk4ZBcNI"
      },
      "source": [
        "# CLT Project - Stage III\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fzpbTSOZBcNP"
      },
      "source": [
        "- **Author:**             Arian Contessotto, Tim Giger, Levin Reichmuth\n",
        "- **Submission Date:**    1 June 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHGNKKFbBcNR"
      },
      "source": [
        "## 1. Setup & Data Loading"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGDdAK4NloL"
      },
      "source": [
        "If running on Colab, install the required packages and load data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMbz9g1GhM8h",
        "outputId": "f4ee390e-7a82-456f-a575-f8376cb53567"
      },
      "outputs": [],
      "source": [
        "# Clone repo with dataset\n",
        "!git clone https://github.com/syX113/hslu-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-su7FTvhjtW",
        "outputId": "c142039c-b845-4820-9950-76895875e69a"
      },
      "outputs": [],
      "source": [
        "# Check if files are loaded\n",
        "!ls hslu-nlp/stage2/annotated/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBNiqJjdBcNT",
        "outputId": "d19fa007-38e6-401f-ff62-375663f9d095"
      },
      "outputs": [],
      "source": [
        "# Required package installation\n",
        "!transformers==4.28.0\n",
        "!pip install torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ppL6jWrIBcNV"
      },
      "source": [
        "### 1.1 Import Packages & Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mikPBmLaBcNV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "from transformers import XLNetTokenizerFast, XLNetForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TsgyJBEWBcNW"
      },
      "source": [
        "### 1.2 Load Annotated Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhuW_gcN404"
      },
      "source": [
        "The final dataframe from stage one is loaded. These data are the basis for stage two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "xzPR79XdBcNX",
        "outputId": "2e5e8a18-6c4e-4b11-f648-e989ef8b0e1a"
      },
      "outputs": [],
      "source": [
        "# Define file name\n",
        "esg_file = '../stage2/annotated/full_llm_annotated.csv' # Local filepath\n",
        "#esg_file = 'hslu-nlp/stage2/annotated/full_llm_annotated.csv' # Filepath on Colab\n",
        "\n",
        "# Define function to load and merge data\n",
        "def load_data(file):\n",
        "\n",
        "    # Load the data\n",
        "    df = pd.read_csv(file, delimiter = '|')\n",
        "\n",
        "    # Apply eval function\n",
        "    df['esg_topics'] = df['esg_topics'].apply(eval)\n",
        "    df['sentence_tokens'] = df['sentence_tokens'].apply(eval)\n",
        "    df['sentiment_llm_continuous'] = df['sentiment_llm_continuous'].apply(eval)\n",
        "    df['sentiment_llm_categorial'] = df['sentiment_llm_categorial'].apply(eval)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data(esg_file)\n",
        "\n",
        "# Print shape and diyplay header\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHZpK87esiJ"
      },
      "source": [
        "### 1.3 Create different Dataframes (Sentences & full Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kas2z-8wsNbe",
        "outputId": "5a7333be-d438-40bd-eb24-c384451ef041"
      },
      "outputs": [],
      "source": [
        "def create_sentence_df(data):\n",
        "\n",
        "    # Select relevant columns\n",
        "    data = data[['internal','sentence_tokens','sentiment_llm_categorial']]\n",
        "\n",
        "    # Explode the tokens, so each sentence is a row\n",
        "    data = data.set_index(['internal']).apply(pd.Series.explode).reset_index()\n",
        "\n",
        "    # Rename the columns and change order\n",
        "    data.rename(columns={'sentence_tokens': 'sentence', 'sentiment_llm_categorial': 'sentiment'}, inplace=True)\n",
        "    data = data[['internal', 'sentence', 'sentiment']]\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['sentence'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Create sentence data\n",
        "sentence_df = create_sentence_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sentence_df.shape)\n",
        "sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "vf-rmV_PesiK",
        "outputId": "9aa43b1b-bd42-490c-ead3-a9d0bffff230"
      },
      "outputs": [],
      "source": [
        "# Function to create document data\n",
        "def create_document_df(data):\n",
        "\n",
        "    # Join tokens\n",
        "    data['document'] = data['sentence_tokens'].apply(' '.join)  # Convert tokens to strings\n",
        "\n",
        "    # Compute the mean of the computed sentiment and discretize it\n",
        "    def discretize_sentiment(value):\n",
        "        if value <= 0.33:\n",
        "            return 0.0\n",
        "        elif value <= 0.66:\n",
        "            return 0.5\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "    data['sentiment'] = data['sentiment_llm_continuous'].apply(np.mean).apply(discretize_sentiment)\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['document'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "\n",
        "    # Return needed columns and discretized mean of the sentiment\n",
        "    return data[['internal', 'document', 'sentiment']]\n",
        "\n",
        "# Create sentence data\n",
        "document_df = create_document_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(document_df.shape)\n",
        "document_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The subsets for the training should have equally distributed classes. In addition, external and internal documents should be represented.  \n",
        "One of these conditions needs to be more \"loose\", we decide class equality is more important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "4IEirqQJmfLm",
        "outputId": "0a1940c5-c50a-452b-948c-361714ed5d13"
      },
      "outputs": [],
      "source": [
        "def balance_sentiment_and_internal(df):\n",
        "    # Get minimum number of observations across sentiment classes\n",
        "    min_internal_count = df['internal'].value_counts().min()\n",
        "    \n",
        "    # Get the minimum number of observations between internal == 0 and internal == 1\n",
        "    min_sentiment_count = min(df[df['sentiment'] == 0].shape[0], df[df['sentiment'] == 1].shape[0], min_internal_count)\n",
        "\n",
        "    # Create \"balanced\" dataframe\n",
        "    balanced_df = pd.concat([df[df['sentiment'] == i].sample(min_sentiment_count, random_state=1) for i in df['sentiment'].unique()])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# Sample the sentence dataframe\n",
        "sub_sentence_df = balance_sentiment_and_internal(sentence_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_sentence_df.shape)\n",
        "sub_sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample the document dataframe\n",
        "sub_document_df = balance_sentiment_and_internal(document_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_document_df.shape)\n",
        "sub_document_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect sampling results\n",
        "print('Sentence subset:')\n",
        "print(sub_sentence_df['internal'].value_counts())\n",
        "print(sub_sentence_df['sentiment'].value_counts())\n",
        "print('\\n')\n",
        "print('Document subset:')\n",
        "print(sub_document_df['internal'].value_counts())\n",
        "print(sub_document_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop uncessary column and reset index\n",
        "document_df = document_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sentence_df = sentence_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sub_sentence_df = sub_sentence_df.drop(columns=['internal']).reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o1UJ8F9FesiK"
      },
      "source": [
        "As a result, the models can be evaluated and trained with 2 approaches:  \n",
        "- A dataframe containing the full document and a discretized mean sentiment of all included sentences\n",
        "- A dataframe containing each sentence with the corresponding discretized sentiment  \n",
        "- Two sampled subset dataframes for moel evaluation\n",
        "\n",
        "\"Discretized\" corresponds to the labels 0.0 (negative), 0.5 (neutral) and 1.0 (positive)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr2iVzZBesiL"
      },
      "source": [
        "## 2. Model Finetuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The evaluation for the model is based on the following conceptual approach:\n",
        "1. Select multiple pretrained (Huggingface) models, based on previous stages\n",
        "2. Train the selected models on a small subset of the full documents and the single sentences to keep the training time short\n",
        "3. Compare the training outcomes of the different models on the two subsets and select the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compute the comparison metrics\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    \n",
        "    # Use the appropriate metrics, since we don't have discrete classes but a continous score \n",
        "    mse = mean_squared_error(y_true=labels, y_pred=pred)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=pred)\n",
        "    r2 = r2_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzglNdb0esiM",
        "outputId": "3cc02fbb-4a45-4320-c9b0-bb78d703c4c8"
      },
      "outputs": [],
      "source": [
        "# Load Tensorboard for training monitoring\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-2Tp63XesiM",
        "outputId": "05ed8c73-846e-44a1-e12d-4e5b5134484e"
      },
      "outputs": [],
      "source": [
        "# Start Tensorboard to monitor training processes\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Finetune Model 1: *distilbert-base-uncased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kwjEdd_oesiL"
      },
      "source": [
        "As a first test, we use the lightweight \"distilbert-base-uncased\" model and fine-tune it on the full documents and the sentences, since the finetuned *\"nlptown/bert-base-multilingual-uncased-sentiment\"* demonstrated high alignment with the gold standard in stage 2.  \n",
        "Since BERT only accepts 512 input word tokens, the full documents are heavyily truncated.  \n",
        "\n",
        "🤗 page: https://huggingface.co/distilbert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWYx-J7esiL",
        "outputId": "8307f8d4-dfe9-4999-9aa5-83f9f32507be"
      },
      "outputs": [],
      "source": [
        "# Define pretrained tokenizer and model\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1) # 1 label to get a continuous score between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the torch datasets to use data in PyTorch and override necessary methods\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6ziqUCesiL"
      },
      "source": [
        "#### Finetune *distilbert-base-uncased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_sentence_df[\"sentence\"])\n",
        "y = list(sub_sentence_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_sent = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_sent = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_sent = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LySMEgQbesiL"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset_distilbert_sent,\n",
        "    eval_dataset=val_dataset_distilbert_sent,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkzspgEResiM",
        "outputId": "544b3439-c9c8-4b11-bfc4-574588c30ef6"
      },
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *distilbert-base-uncased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_document_df[\"document\"])\n",
        "y = list(sub_document_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_doc = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_doc = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_doc = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args_distilbert = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args_distilbert,\n",
        "    train_dataset=train_dataset_distilbert_doc,\n",
        "    eval_dataset=val_dataset_distilbert_doc,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Finetune Model 2: *roberta-base*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a second model for the comparison, we choose RoBERTa. It is a further development of BERT and should perform better.  \n",
        "\n",
        "This model benefits substantially from extended training duration, larger data batches, and an increase in dataset size. Its performance further increases by eliminating the next sentence prediction objective and integrating longer sequences during training.  \n",
        "Lastly, the model's optimization is boosted by dynamically altering the masking pattern applied to the training data.\n",
        "\n",
        "Reference: https://arxiv.org/pdf/1907.11692.pdf  \n",
        "🤗 page: https://huggingface.co/roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load default methods again, since a few are overwritten for destillbert\n",
        "from datasets import Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the tokenizer for RoBERTa\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenize_and_format_sentence(examples):\n",
        "\n",
        "    # Tokenize the text and map sentiment to label\n",
        "    tokenized_inputs = tokenizer(examples['sentence'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    # Return both the tokenized inputs and labels\n",
        "    return {**tokenized_inputs, 'labels': labels}\n",
        "\n",
        "def tokenize_and_format_document(examples):\n",
        "    # Same as above for documents\n",
        "    tokenized_inputs = tokenizer(examples['document'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    return {**tokenized_inputs, 'labels': labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the base RoBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_sent = train_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "val_dataset_roberta_sent = val_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "test_dataset_roberta_sent = test_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_sent,\n",
        "    eval_dataset=val_dataset_roberta_sent\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_doc = train_dataset.map(tokenize_and_format_document, batched=True)\n",
        "val_dataset_roberta_doc = val_dataset.map(tokenize_and_format_document, batched=True)\n",
        "test_dataset_roberta_doc = test_dataset.map(tokenize_and_format_document, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_doc,\n",
        "    eval_dataset=val_dataset_roberta_doc\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Finetune Model 3: *xlnet-base-cased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XLNet is a pretraining model for natural language processing tasks that combines the advantages of both autoregressive language models and denoising autoencoding models like BERT. \n",
        "Unlike BERT, XLNet mitigates dependency issues between masked positions and avoids a pretrain-finetune discrepancy by employing a generalized autoregressive method. \n",
        "This approach allows for learning bidirectional contexts by maximizing expected likelihood over all possible factorization orders. \n",
        "Furthermore, it integrates the strengths of Transformer-XL, a leading autoregressive model, into its pretraining procedure. \n",
        "Empirical evidence suggests that XLNet surpasses BERT in performance across a range of tasks including question answering, natural language inference, sentiment analysis, and document ranking.\n",
        "\n",
        "Reference: https://arxiv.org/abs/1906.08237  \n",
        "🤗 page: https://huggingface.co/xlnet-base-cased\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased')\n",
        "# Load the XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjust compute metrics function for XLNet\n",
        "def compute_metrics_xlnet(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.detach().numpy()\n",
        "    labels = labels.detach().numpy()\n",
        "    \n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    mae = mean_absolute_error(labels, predictions)\n",
        "    r2 = r2_score(labels, predictions)\n",
        "\n",
        "    return {'mse': mse, 'mae': mae, 'r2': r2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs\n",
        "    inputs = tokenizer(sentences, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors and resize to match input dimensions\n",
        "    labels = torch.tensor(labels).unsqueeze(1).float()\n",
        "\n",
        "    return inputs.input_ids, labels\n",
        "\n",
        "# Create torch Dataset and adjust methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_sentence_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['sentence'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['sentence'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['sentence'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_sent = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_sent = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_sent = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_sent,\n",
        "    eval_dataset=val_dataset_xlnet_sent,\n",
        "    compute_metrics=compute_metrics_xlnet,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_document_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['document'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['document'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['document'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_doc = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_doc = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_doc = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_doc,\n",
        "    eval_dataset=val_dataset_xlnet_doc,\n",
        "    compute_metrics=compute_metrics_xlnet,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Finetune Model 4: *flan-t5-base* (not working correctly)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🤗 page: https://huggingface.co/google/flan-t5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Use correct Dataset class and adjust needed methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels.float()\n",
        "        self.decoder_input_ids = torch.ones((len(labels),1), dtype=torch.long) # Initialize with start token\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        item['decoder_input_ids'] = self.decoder_input_ids[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs with added task-specific prefix (\"sentiment\")\n",
        "    inputs = tokenizer([\"sentiment: \" + sentence for sentence in sentences], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors\n",
        "    labels = torch.tensor(labels.to_numpy())\n",
        "\n",
        "    dataset = SentimentDataset(inputs, labels)\n",
        "    return dataset\n",
        "\n",
        "sentence_data = sub_sentence_df['sentence']\n",
        "label_data = sub_sentence_df['sentiment']\n",
        "\n",
        "train_frac = 0.8\n",
        "train_size = int(train_frac * len(sentence_data))\n",
        "\n",
        "train_sentences = sentence_data[:train_size]\n",
        "train_labels = label_data[:train_size]\n",
        "\n",
        "val_sentences = sentence_data[train_size:]\n",
        "val_labels = label_data[train_size:]\n",
        "\n",
        "train_dataset = prepare_data(train_sentences, train_labels)\n",
        "val_dataset = prepare_data(val_sentences, val_labels)\n",
        "\n",
        "def compute_metrics_flan(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Reduce predictions to a single value per sequence (e.g., using mean)\n",
        "    predictions = predictions.mean(dim=-1)\n",
        "\n",
        "    mse = mean_squared_error(y_true=labels, y_pred=predictions)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=predictions)\n",
        "    r2 = r2_score(y_true=labels, y_pred=predictions)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
        "\n",
        "class SentimentTrainer(Trainer):\n",
        "    def predict(self, test_dataset):\n",
        "        predictions, labels, _ = super().predict(test_dataset)\n",
        "        # convert predicted token ids to float values\n",
        "        predictions = [float(tokenizer.decode(pred)) for pred in predictions]\n",
        "        return predictions, labels\n",
        "    \n",
        "    # Adjust loss function to regression\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Reduce logits to a single value per sequence (e.g., using mean)\n",
        "        logits = logits.mean(dim=-1)\n",
        "\n",
        "        # Use MSE loss for regression\n",
        "        loss_fct = torch.nn.MSELoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/flant5_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "trainer = SentimentTrainer(\n",
        "    model=model,              \n",
        "    args=training_args, \n",
        "    compute_metrics=compute_metrics_flan,     \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/flant5_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T5 models are normally used for text-to-text tasks. Therefore, fine-tuning T5 for a classification task with a continous prediction between 0 and 1 is a bit of a diversion. Still, above code works and the training can be started.  \n",
        "But the user-defined loss function does not work properly (it does not drop, but shows 0 throughout the training), and there is also uncertainty about the correct encodings.  \n",
        "\n",
        "Therefore, this model is not considered."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The finetuned models are evaluated based on MSE, MAE and R2. In addition, the test datasets are used to test the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained distilbert model\n",
        "model_distilbert_sent = BertForSequenceClassification.from_pretrained('./models/distilbert_sentences/', num_labels=1)\n",
        "# Define distilbert test trainer\n",
        "trainer_distilbert_sent = Trainer(model_distilbert_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_distilbert_sent = trainer_distilbert_sent.predict(test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained RoBERTa model\n",
        "model_roberta_sent = RobertaForSequenceClassification.from_pretrained('./models/roberta_sentences/', num_labels=1)\n",
        "# Define RoBERTa test trainer\n",
        "trainer_roberta_sent = Trainer(model_roberta_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_roberta_sent = trainer_roberta_sent.predict(test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained xlnet model\n",
        "model_xlnet_sent = XLNetForSequenceClassification.from_pretrained('./models/xlnet_sentences/', num_labels=1)\n",
        "# Define xlnet test trainer\n",
        "trainer_xlnet_sent = Trainer(model_xlnet_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_xlnet_sent = trainer_xlnet_sent.predict(test_dataset_xlnet_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_distilbert_sent.evaluate(eval_dataset=test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_roberta_sent.evaluate(eval_dataset=test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_xlnet_sent.evaluate(eval_dataset=test_dataset_xlnet_sent)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Tensorboard to inspect the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Tensorboard to monitor training process\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset_distilbert_doc\n",
        "# test_dataset_roberta_doc\n",
        "# test_dataset_xlnet_doc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c_FFqFrresiO"
      },
      "source": [
        "## 4. Hyperparameter Tuning for selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYcomVCfesiP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Full Training of selected Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed up the full training, PEFT (https://github.com/huggingface/peft) is considered.  \n",
        "RoBERTa supports LoRa, Prefix Tuning, P-Tuning and Prompt Tuning: https://github.com/huggingface/peft#sequence-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation of fully trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sentiment Prediction with selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rK7BZAfyx_rY"
      },
      "source": [
        "## 8. Compare internal vs. external"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
