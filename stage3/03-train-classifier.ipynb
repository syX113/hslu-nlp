{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UyvrKk4ZBcNI"
      },
      "source": [
        "# CLT Project - Stage III\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fzpbTSOZBcNP"
      },
      "source": [
        "- **Author:**             Arian Contessotto, Tim Giger, Levin Reichmuth\n",
        "- **Submission Date:**    1 June 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHGNKKFbBcNR"
      },
      "source": [
        "## 1. Setup & Data Loading"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGDdAK4NloL"
      },
      "source": [
        "If running on Colab, install the required packages and load data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMbz9g1GhM8h",
        "outputId": "f4ee390e-7a82-456f-a575-f8376cb53567"
      },
      "outputs": [],
      "source": [
        "# Clone repo with dataset\n",
        "!git clone https://github.com/syX113/hslu-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-su7FTvhjtW",
        "outputId": "c142039c-b845-4820-9950-76895875e69a"
      },
      "outputs": [],
      "source": [
        "# Check if files are loaded\n",
        "!ls hslu-nlp/stage2/annotated/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBNiqJjdBcNT",
        "outputId": "d19fa007-38e6-401f-ff62-375663f9d095"
      },
      "outputs": [],
      "source": [
        "# Required package installation\n",
        "!transformers==4.28.0\n",
        "!pip install torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ppL6jWrIBcNV"
      },
      "source": [
        "### 1.1 Import Packages & Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mikPBmLaBcNV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-27 18:07:52.249868: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-27 18:17:05.413986: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-27 18:17:06.319960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "from transformers import XLNetTokenizerFast, XLNetForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhuW_gcN404"
      },
      "source": [
        "The final dataframe from stage one is loaded. These data are the basis for stage two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "xzPR79XdBcNX",
        "outputId": "2e5e8a18-6c4e-4b11-f648-e989ef8b0e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11071, 17)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>datatype</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>domain</th>\n",
              "      <th>esg_topics</th>\n",
              "      <th>internal</th>\n",
              "      <th>symbol</th>\n",
              "      <th>sentence_tokens</th>\n",
              "      <th>market_cap_in_usd_b</th>\n",
              "      <th>sector</th>\n",
              "      <th>industry</th>\n",
              "      <th>year_month</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>sentiment_llm_continuous</th>\n",
              "      <th>sentiment_llm_categorial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beiersdorf</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>BeiersdorfAG Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[CleanWater, GHGEmission, ProductLiability, Va...</td>\n",
              "      <td>1</td>\n",
              "      <td>BEI</td>\n",
              "      <td>[brands strategy sustainability agenda care be...</td>\n",
              "      <td>25.99</td>\n",
              "      <td>Consumer Staples</td>\n",
              "      <td>Household &amp; Personal Products</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.4510161280632019, 0.6138720512390137, 0.226...</td>\n",
              "      <td>[0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deutsche Telekom</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>DeutscheTelekomAG Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[DataSecurity, Iso50001, GlobalWarming, Produc...</td>\n",
              "      <td>1</td>\n",
              "      <td>DTE</td>\n",
              "      <td>[management facts, deutsche telekom cr report,...</td>\n",
              "      <td>101.78</td>\n",
              "      <td>Communication Services</td>\n",
              "      <td>Telecom Services</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.35756340622901917, 0.29088783264160156, 0.3...</td>\n",
              "      <td>[0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vonovia</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>VonoviaSE Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Whistleblowing, DataSecurity, Vaccine, GHGEmi...</td>\n",
              "      <td>1</td>\n",
              "      <td>VNA</td>\n",
              "      <td>[sustainable future, sustainability report dea...</td>\n",
              "      <td>20.35</td>\n",
              "      <td>Real Estate</td>\n",
              "      <td>Real Estate Services</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.4570336639881134, 0.45287153124809265, 0.26...</td>\n",
              "      <td>[0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Merck</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>MerckKGaA Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[DataSecurity, DataMisuse, DrugResistance, Iso...</td>\n",
              "      <td>1</td>\n",
              "      <td>MRK</td>\n",
              "      <td>[management employees profile attractive emplo...</td>\n",
              "      <td>87.64</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Drug Manufacturers—Specialty &amp; Generic</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.36378589272499084, 0.6118267178535461, 0.48...</td>\n",
              "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MTU</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>MTUAeroEngines Sustainability Report 2020</td>\n",
              "      <td>2020-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[WorkLifeBalance, Corruption, AirQuality, Data...</td>\n",
              "      <td>1</td>\n",
              "      <td>MTX</td>\n",
              "      <td>[sustainability goes far beyond climate action...</td>\n",
              "      <td>12.24</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Aerospace &amp; Defense</td>\n",
              "      <td>2020-03</td>\n",
              "      <td>2020</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.46082836389541626, 0.46208637952804565, 0.4...</td>\n",
              "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            company               datatype  \\\n",
              "0        Beiersdorf  sustainability_report   \n",
              "1  Deutsche Telekom  sustainability_report   \n",
              "2           Vonovia  sustainability_report   \n",
              "3             Merck  sustainability_report   \n",
              "4               MTU  sustainability_report   \n",
              "\n",
              "                                          title        date domain  \\\n",
              "0       BeiersdorfAG Sustainability Report 2021  2021-03-31    NaN   \n",
              "1  DeutscheTelekomAG Sustainability Report 2021  2021-03-31    NaN   \n",
              "2          VonoviaSE Sustainability Report 2021  2021-03-31    NaN   \n",
              "3          MerckKGaA Sustainability Report 2021  2021-03-31    NaN   \n",
              "4     MTUAeroEngines Sustainability Report 2020  2020-03-31    NaN   \n",
              "\n",
              "                                          esg_topics  internal symbol  \\\n",
              "0  [CleanWater, GHGEmission, ProductLiability, Va...         1    BEI   \n",
              "1  [DataSecurity, Iso50001, GlobalWarming, Produc...         1    DTE   \n",
              "2  [Whistleblowing, DataSecurity, Vaccine, GHGEmi...         1    VNA   \n",
              "3  [DataSecurity, DataMisuse, DrugResistance, Iso...         1    MRK   \n",
              "4  [WorkLifeBalance, Corruption, AirQuality, Data...         1    MTX   \n",
              "\n",
              "                                     sentence_tokens  market_cap_in_usd_b  \\\n",
              "0  [brands strategy sustainability agenda care be...                25.99   \n",
              "1  [management facts, deutsche telekom cr report,...               101.78   \n",
              "2  [sustainable future, sustainability report dea...                20.35   \n",
              "3  [management employees profile attractive emplo...                87.64   \n",
              "4  [sustainability goes far beyond climate action...                12.24   \n",
              "\n",
              "                   sector                                industry year_month  \\\n",
              "0        Consumer Staples           Household & Personal Products    2021-03   \n",
              "1  Communication Services                        Telecom Services    2021-03   \n",
              "2             Real Estate                    Real Estate Services    2021-03   \n",
              "3              Healthcare  Drug Manufacturers—Specialty & Generic    2021-03   \n",
              "4             Industrials                     Aerospace & Defense    2020-03   \n",
              "\n",
              "   year  month                           sentiment_llm_continuous  \\\n",
              "0  2021      3  [0.4510161280632019, 0.6138720512390137, 0.226...   \n",
              "1  2021      3  [0.35756340622901917, 0.29088783264160156, 0.3...   \n",
              "2  2021      3  [0.4570336639881134, 0.45287153124809265, 0.26...   \n",
              "3  2021      3  [0.36378589272499084, 0.6118267178535461, 0.48...   \n",
              "4  2020      3  [0.46082836389541626, 0.46208637952804565, 0.4...   \n",
              "\n",
              "                            sentiment_llm_categorial  \n",
              "0  [0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...  \n",
              "1  [0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...  \n",
              "2  [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...  \n",
              "3  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...  \n",
              "4  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define file name\n",
        "esg_file = '../stage2/annotated/full_llm_annotated.csv' # Local filepath\n",
        "#esg_file = 'hslu-nlp/stage2/annotated/full_llm_annotated.csv' # Filepath on Colab\n",
        "\n",
        "# Define function to load and merge data\n",
        "def load_data(file):\n",
        "\n",
        "    # Load the data\n",
        "    df = pd.read_csv(file, delimiter = '|')\n",
        "\n",
        "    # Apply eval function\n",
        "    df['esg_topics'] = df['esg_topics'].apply(eval)\n",
        "    df['sentence_tokens'] = df['sentence_tokens'].apply(eval)\n",
        "    df['sentiment_llm_continuous'] = df['sentiment_llm_continuous'].apply(eval)\n",
        "    df['sentiment_llm_categorial'] = df['sentiment_llm_categorial'].apply(eval)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data(esg_file)\n",
        "\n",
        "# Print shape and diyplay header\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHZpK87esiJ"
      },
      "source": [
        "### 1.3 Create different Dataframes (Sentences & full Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kas2z-8wsNbe",
        "outputId": "5a7333be-d438-40bd-eb24-c384451ef041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(678529, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>brands strategy sustainability agenda care bey...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>successfully reduced carbon footprint absolute...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>end consumer business returned levels reduced ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>decoupling human economic activity natural res...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>inspired beiersdorf ambitious sustainability a...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   internal                                           sentence  sentiment\n",
              "0         1  brands strategy sustainability agenda care bey...        0.5\n",
              "1         1  successfully reduced carbon footprint absolute...        0.5\n",
              "2         1  end consumer business returned levels reduced ...        0.0\n",
              "3         1  decoupling human economic activity natural res...        0.0\n",
              "4         1  inspired beiersdorf ambitious sustainability a...        0.5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_sentence_df(data):\n",
        "\n",
        "    # Select relevant columns\n",
        "    data = data[['internal','sentence_tokens','sentiment_llm_categorial']]\n",
        "\n",
        "    # Explode the tokens, so each sentence is a row\n",
        "    data = data.set_index(['internal']).apply(pd.Series.explode).reset_index()\n",
        "\n",
        "    # Rename the columns and change order\n",
        "    data.rename(columns={'sentence_tokens': 'sentence', 'sentiment_llm_categorial': 'sentiment'}, inplace=True)\n",
        "    data = data[['internal', 'sentence', 'sentiment']]\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['sentence'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Create sentence data\n",
        "sentence_df = create_sentence_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sentence_df.shape)\n",
        "sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "vf-rmV_PesiK",
        "outputId": "9aa43b1b-bd42-490c-ead3-a9d0bffff230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11071, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>document</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>brands strategy sustainability agenda care bey...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>management facts deutsche telekom cr report th...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>sustainable future sustainability report dear ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>management employees profile attractive employ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>sustainability goes far beyond climate action ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   internal                                           document  sentiment\n",
              "0         1  brands strategy sustainability agenda care bey...        0.5\n",
              "1         1  management facts deutsche telekom cr report th...        0.5\n",
              "2         1  sustainable future sustainability report dear ...        0.5\n",
              "3         1  management employees profile attractive employ...        0.5\n",
              "4         1  sustainability goes far beyond climate action ...        0.5"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to create document data\n",
        "def create_document_df(data):\n",
        "\n",
        "    # Join tokens\n",
        "    data['document'] = data['sentence_tokens'].apply(' '.join)  # Convert tokens to strings\n",
        "\n",
        "    # Compute the mean of the computed sentiment and discretize it\n",
        "    def discretize_sentiment(value):\n",
        "        if value <= 0.33:\n",
        "            return 0.0\n",
        "        elif value <= 0.66:\n",
        "            return 0.5\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "    data['sentiment'] = data['sentiment_llm_continuous'].apply(np.mean).apply(discretize_sentiment)\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['document'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "\n",
        "    # Return needed columns and discretized mean of the sentiment\n",
        "    return data[['internal', 'document', 'sentiment']]\n",
        "\n",
        "# Create sentence data\n",
        "document_df = create_document_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(document_df.shape)\n",
        "document_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The subsets for the training should have equally distributed classes. In addition, external and internal documents should be represented.  \n",
        "One of these conditions needs to be more \"loose\", we decide class equality is more important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "4IEirqQJmfLm",
        "outputId": "0a1940c5-c50a-452b-948c-361714ed5d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(103812, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>482121</th>\n",
              "      <td>0</td>\n",
              "      <td>july incyte eli lilly announced fda would meet...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459567</th>\n",
              "      <td>0</td>\n",
              "      <td>still cautious highly contagious delta strain ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110344</th>\n",
              "      <td>1</td>\n",
              "      <td>march first publicprivate peer employees tied ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267939</th>\n",
              "      <td>0</td>\n",
              "      <td>content plans featuring presentation followed ...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315677</th>\n",
              "      <td>0</td>\n",
              "      <td>pubmed scopus google scholar however link nets...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        internal                                           sentence  sentiment\n",
              "482121         0  july incyte eli lilly announced fda would meet...        0.5\n",
              "459567         0  still cautious highly contagious delta strain ...        0.5\n",
              "110344         1  march first publicprivate peer employees tied ...        0.5\n",
              "267939         0  content plans featuring presentation followed ...        0.5\n",
              "315677         0  pubmed scopus google scholar however link nets...        0.5"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def balance_sentiment_and_internal(df):\n",
        "    # Get minimum number of observations across sentiment classes\n",
        "    min_internal_count = df['internal'].value_counts().min()\n",
        "    \n",
        "    # Get the minimum number of observations between internal == 0 and internal == 1\n",
        "    min_sentiment_count = min(df[df['sentiment'] == 0].shape[0], df[df['sentiment'] == 1].shape[0], min_internal_count)\n",
        "\n",
        "    # Create \"balanced\" dataframe\n",
        "    balanced_df = pd.concat([df[df['sentiment'] == i].sample(min_sentiment_count, random_state=1) for i in df['sentiment'].unique()])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# Sample the sentence dataframe\n",
        "sub_sentence_df = balance_sentiment_and_internal(sentence_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_sentence_df.shape)\n",
        "sub_sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(186, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>document</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10179</th>\n",
              "      <td>0</td>\n",
              "      <td>dgapnews ag key word quarterly interim stateme...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2292</th>\n",
              "      <td>0</td>\n",
              "      <td>president fraunhofer institute ceramic technol...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10338</th>\n",
              "      <td>0</td>\n",
              "      <td>yet father granted biopic still waiting twenty...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5472</th>\n",
              "      <td>0</td>\n",
              "      <td>stepped gear dedicated taskforce held inaugura...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8299</th>\n",
              "      <td>0</td>\n",
              "      <td>business technology platform critical piece la...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       internal                                           document  sentiment\n",
              "10179         0  dgapnews ag key word quarterly interim stateme...        0.5\n",
              "2292          0  president fraunhofer institute ceramic technol...        0.5\n",
              "10338         0  yet father granted biopic still waiting twenty...        0.5\n",
              "5472          0  stepped gear dedicated taskforce held inaugura...        0.5\n",
              "8299          0  business technology platform critical piece la...        0.5"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample the document dataframe\n",
        "sub_document_df = balance_sentiment_and_internal(document_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_document_df.shape)\n",
        "sub_document_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence subset:\n",
            "0    72896\n",
            "1    30916\n",
            "Name: internal, dtype: int64\n",
            "0.5    34604\n",
            "0.0    34604\n",
            "1.0    34604\n",
            "Name: sentiment, dtype: int64\n",
            "\n",
            "\n",
            "Document subset:\n",
            "0    186\n",
            "Name: internal, dtype: int64\n",
            "0.5    62\n",
            "1.0    62\n",
            "0.0    62\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Inspect sampling results\n",
        "print('Sentence subset:')\n",
        "print(sub_sentence_df['internal'].value_counts())\n",
        "print(sub_sentence_df['sentiment'].value_counts())\n",
        "print('\\n')\n",
        "print('Document subset:')\n",
        "print(sub_document_df['internal'].value_counts())\n",
        "print(sub_document_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop uncessary column and reset index\n",
        "document_df = document_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sentence_df = sentence_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sub_sentence_df = sub_sentence_df.drop(columns=['internal']).reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o1UJ8F9FesiK"
      },
      "source": [
        "As a result, the models can be evaluated and trained with 2 approaches:  \n",
        "- A dataframe containing the full document and a discretized mean sentiment of all included sentences\n",
        "- A dataframe containing each sentence with the corresponding discretized sentiment  \n",
        "- Two sampled subset dataframes for moel evaluation\n",
        "\n",
        "\"Discretized\" corresponds to the labels 0.0 (negative), 0.5 (neutral) and 1.0 (positive)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr2iVzZBesiL"
      },
      "source": [
        "## 2. Model Finetuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The evaluation for the model is based on the following conceptual approach:\n",
        "1. Select multiple pretrained (Huggingface) models, based on previous stages\n",
        "2. Train the selected models on a small subset of the full documents and the single sentences to keep the training time short\n",
        "3. Compare the training outcomes of the different models on the two subsets and select the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compute the comparison metrics\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    \n",
        "    # Use the appropriate metrics, since we don't have discrete classes but a continous score \n",
        "    mse = mean_squared_error(y_true=labels, y_pred=pred)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=pred)\n",
        "    r2 = r2_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fzglNdb0esiM",
        "outputId": "3cc02fbb-4a45-4320-c9b0-bb78d703c4c8"
      },
      "outputs": [],
      "source": [
        "# Load Tensorboard for training monitoring\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D-2Tp63XesiM",
        "outputId": "05ed8c73-846e-44a1-e12d-4e5b5134484e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-b910f9685133b6b4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-b910f9685133b6b4\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6010;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Start Tensorboard to monitor training processes\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Finetune Model 1: *distilbert-base-uncased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kwjEdd_oesiL"
      },
      "source": [
        "As a first test, we use the lightweight \"distilbert-base-uncased\" model and fine-tune it on the full documents and the sentences, since the finetuned *\"nlptown/bert-base-multilingual-uncased-sentiment\"* demonstrated high alignment with the gold standard in stage 2.  \n",
        "Since BERT only accepts 512 input word tokens, the full documents are heavyily truncated.  \n",
        "\n",
        "🤗 page: https://huggingface.co/distilbert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWYx-J7esiL",
        "outputId": "8307f8d4-dfe9-4999-9aa5-83f9f32507be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n",
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'classifier.weight', 'classifier.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'embeddings.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define pretrained tokenizer and model\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1) # 1 label to get a continuous score between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the torch datasets to use data in PyTorch and override necessary methods\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6ziqUCesiL"
      },
      "source": [
        "#### Finetune *distilbert-base-uncased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_sentence_df[\"sentence\"])\n",
        "y = list(sub_sentence_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_sent = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_sent = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_sent = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LySMEgQbesiL"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset_distilbert_sent,\n",
        "    eval_dataset=val_dataset_distilbert_sent,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gkzspgEResiM",
        "outputId": "544b3439-c9c8-4b11-bfc4-574588c30ef6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6813 08:10 < 47:35, 2.04 it/s, Epoch 0.44/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1945' max='1947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1945/1947 01:15 < 00:00, 25.81 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *distilbert-base-uncased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_document_df[\"document\"])\n",
        "y = list(sub_document_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_doc = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_doc = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_doc = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args_distilbert = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args_distilbert,\n",
        "    train_dataset=train_dataset_distilbert_doc,\n",
        "    eval_dataset=val_dataset_distilbert_doc,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 11/800 00:02 < 03:57, 3.33 it/s, Epoch 1.21/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/7 00:00 < 00:00, 41.49 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Finetune Model 2: *roberta-base*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a second model for the comparison, we choose RoBERTa. It is a further development of BERT and should perform better.  \n",
        "\n",
        "This model benefits substantially from extended training duration, larger data batches, and an increase in dataset size. Its performance further increases by eliminating the next sentence prediction objective and integrating longer sequences during training.  \n",
        "Lastly, the model's optimization is boosted by dynamically altering the masking pattern applied to the training data.\n",
        "\n",
        "Reference: https://arxiv.org/pdf/1907.11692.pdf  \n",
        "🤗 page: https://huggingface.co/roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load default methods again, since a few are overwritten for destillbert\n",
        "from datasets import Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the tokenizer for RoBERTa\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenize_and_format_sentence(examples):\n",
        "\n",
        "    # Tokenize the text and map sentiment to label\n",
        "    tokenized_inputs = tokenizer(examples['sentence'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    # Return both the tokenized inputs and labels\n",
        "    return {**tokenized_inputs, 'labels': labels}\n",
        "\n",
        "def tokenize_and_format_document(examples):\n",
        "    # Same as above for documents\n",
        "    tokenized_inputs = tokenizer(examples['document'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    return {**tokenized_inputs, 'labels': labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the base RoBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5326d75a3237431c9ac6765e307d6a7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/72668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976117148d04478db8d11ec615c9caa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15572 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db90c6f61cda4230a396217a37e7c946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15572 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_sent = train_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "val_dataset_roberta_sent = val_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "test_dataset_roberta_sent = test_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_sent,\n",
        "    eval_dataset=val_dataset_roberta_sent\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6813 08:24 < 48:52, 1.98 it/s, Epoch 0.44/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1943' max='1947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1943/1947 01:16 < 00:00, 25.35 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ed19dfa41e24833807784b854603abc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4303dce42a145939a94c29876436c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63f3f053cbd449e3bdaf5c063de1dec2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_doc = train_dataset.map(tokenize_and_format_document, batched=True)\n",
        "val_dataset_roberta_doc = val_dataset.map(tokenize_and_format_document, batched=True)\n",
        "test_dataset_roberta_doc = test_dataset.map(tokenize_and_format_document, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_doc,\n",
        "    eval_dataset=val_dataset_roberta_doc\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 11/800 00:02 < 04:05, 3.21 it/s, Epoch 1.21/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/7 00:00 < 00:00, 39.84 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Finetune Model 3: *xlnet-base-cased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XLNet is a pretraining model for natural language processing tasks that combines the advantages of both autoregressive language models and denoising autoencoding models like BERT. \n",
        "Unlike BERT, XLNet mitigates dependency issues between masked positions and avoids a pretrain-finetune discrepancy by employing a generalized autoregressive method. \n",
        "This approach allows for learning bidirectional contexts by maximizing expected likelihood over all possible factorization orders. \n",
        "Furthermore, it integrates the strengths of Transformer-XL, a leading autoregressive model, into its pretraining procedure. \n",
        "Empirical evidence suggests that XLNet surpasses BERT in performance across a range of tasks including question answering, natural language inference, sentiment analysis, and document ranking.\n",
        "\n",
        "Reference: https://arxiv.org/abs/1906.08237  \n",
        "🤗 page: https://huggingface.co/xlnet-base-cased\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased')\n",
        "# Load the XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjust compute metrics function for XLNet\n",
        "def compute_metrics_xlnet(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.detach().numpy()\n",
        "    labels = labels.detach().numpy()\n",
        "    \n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    mae = mean_absolute_error(labels, predictions)\n",
        "    r2 = r2_score(labels, predictions)\n",
        "\n",
        "    return {'mse': mse, 'mae': mae, 'r2': r2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs\n",
        "    inputs = tokenizer(sentences, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors and resize to match input dimensions\n",
        "    labels = torch.tensor(labels).unsqueeze(1).float()\n",
        "\n",
        "    return inputs.input_ids, labels\n",
        "\n",
        "# Create torch Dataset and adjust methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_sentence_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['sentence'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['sentence'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['sentence'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_sent = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_sent = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_sent = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_sent,\n",
        "    eval_dataset=val_dataset_xlnet_sent,\n",
        "    compute_metrics=compute_metrics_xlnet,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6813' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6813 17:28 < 1:41:41, 0.95 it/s, Epoch 0.44/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6489' max='6489' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6489/6489 14:50]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'detach'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      3\u001b[0m \u001b[39m# Train pre-trained model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      5\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39m\"\u001b[39m\u001b[39m./models/xlnet_sentences\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1665\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1666\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1667\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1668\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1669\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:2019\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2017\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 2019\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   2020\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2021\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:2300\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2298\u001b[0m         metrics\u001b[39m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2299\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2300\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2303\u001b[0m \u001b[39m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:3029\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3026\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3028\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3029\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   3030\u001b[0m     eval_dataloader,\n\u001b[1;32m   3031\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3032\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3033\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3034\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   3035\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   3036\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   3037\u001b[0m )\n\u001b[1;32m   3039\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   3040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
            "File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3314\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3315\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[1;32m   3316\u001b[0m         )\n\u001b[1;32m   3317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3318\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[1;32m   3319\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3320\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
            "Cell \u001b[0;32mIn[31], line 4\u001b[0m, in \u001b[0;36mcompute_metrics_xlnet\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_metrics_xlnet\u001b[39m(eval_pred):\n\u001b[1;32m      3\u001b[0m     logits, labels \u001b[39m=\u001b[39m eval_pred\n\u001b[0;32m----> 4\u001b[0m     predictions \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(labels, predictions)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
          ]
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_document_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['document'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['document'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['document'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_doc = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_doc = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_doc = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_doc,\n",
        "    eval_dataset=val_dataset_xlnet_doc,\n",
        "    compute_metrics=compute_metrics_xlnet,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Finetune Model 4: *flan-t5-base* (not working correctly)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🤗 page: https://huggingface.co/google/flan-t5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Use correct Dataset class and adjust needed methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels.float()\n",
        "        self.decoder_input_ids = torch.ones((len(labels),1), dtype=torch.long) # Initialize with start token\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        item['decoder_input_ids'] = self.decoder_input_ids[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs with added task-specific prefix (\"sentiment\")\n",
        "    inputs = tokenizer([\"sentiment: \" + sentence for sentence in sentences], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors\n",
        "    labels = torch.tensor(labels.to_numpy())\n",
        "\n",
        "    dataset = SentimentDataset(inputs, labels)\n",
        "    return dataset\n",
        "\n",
        "sentence_data = sub_sentence_df['sentence']\n",
        "label_data = sub_sentence_df['sentiment']\n",
        "\n",
        "train_frac = 0.8\n",
        "train_size = int(train_frac * len(sentence_data))\n",
        "\n",
        "train_sentences = sentence_data[:train_size]\n",
        "train_labels = label_data[:train_size]\n",
        "\n",
        "val_sentences = sentence_data[train_size:]\n",
        "val_labels = label_data[train_size:]\n",
        "\n",
        "train_dataset = prepare_data(train_sentences, train_labels)\n",
        "val_dataset = prepare_data(val_sentences, val_labels)\n",
        "\n",
        "def compute_metrics_flan(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Reduce predictions to a single value per sequence (e.g., using mean)\n",
        "    predictions = predictions.mean(dim=-1)\n",
        "\n",
        "    mse = mean_squared_error(y_true=labels, y_pred=predictions)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=predictions)\n",
        "    r2 = r2_score(y_true=labels, y_pred=predictions)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
        "\n",
        "class SentimentTrainer(Trainer):\n",
        "    def predict(self, test_dataset):\n",
        "        predictions, labels, _ = super().predict(test_dataset)\n",
        "        # convert predicted token ids to float values\n",
        "        predictions = [float(tokenizer.decode(pred)) for pred in predictions]\n",
        "        return predictions, labels\n",
        "    \n",
        "    # Adjust loss function to regression\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Reduce logits to a single value per sequence (e.g., using mean)\n",
        "        logits = logits.mean(dim=-1)\n",
        "\n",
        "        # Use MSE loss for regression\n",
        "        loss_fct = torch.nn.MSELoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/flant5_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "trainer = SentimentTrainer(\n",
        "    model=model,              \n",
        "    args=training_args, \n",
        "    compute_metrics=compute_metrics_flan,     \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/flant5_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T5 models are normally used for text-to-text tasks. Therefore, fine-tuning T5 for a classification task with a continous prediction between 0 and 1 is a bit of a diversion. Still, above code works and the training can be started.  \n",
        "But the user-defined loss function does not work properly (it does not drop, but shows 0 throughout the training), and there is also uncertainty about the correct encodings.  \n",
        "\n",
        "Therefore, this model is not considered."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The finetuned models are evaluated based on MSE, MAE and R2. In addition, the test datasets are used to test the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained distilbert model\n",
        "model_distilbert_sent = BertForSequenceClassification.from_pretrained('./models/distilbert_sentences/', num_labels=1)\n",
        "# Define distilbert test trainer\n",
        "trainer_distilbert_sent = Trainer(model_distilbert_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_distilbert_sent = trainer_distilbert_sent.predict(test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained RoBERTa model\n",
        "model_roberta_sent = RobertaForSequenceClassification.from_pretrained('./models/roberta_sentences/', num_labels=1)\n",
        "# Define RoBERTa test trainer\n",
        "trainer_roberta_sent = Trainer(model_roberta_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_roberta_sent = trainer_roberta_sent.predict(test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load trained xlnet model\n",
        "model_xlnet_sent = XLNetForSequenceClassification.from_pretrained('./models/xlnet_sentences/', num_labels=1)\n",
        "# Define xlnet test trainer\n",
        "trainer_xlnet_sent = Trainer(model_xlnet_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_xlnet_sent = trainer_xlnet_sent.predict(test_dataset_xlnet_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_distilbert_sent.evaluate(eval_dataset=test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_roberta_sent.evaluate(eval_dataset=test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_xlnet_sent.evaluate(eval_dataset=test_dataset_xlnet_sent)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Tensorboard to inspect the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Tensorboard to monitor training process\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset_distilbert_doc\n",
        "# test_dataset_roberta_doc\n",
        "# test_dataset_xlnet_doc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c_FFqFrresiO"
      },
      "source": [
        "## 4. Hyperparameter Tuning for selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYcomVCfesiP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Full Training of selected Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed up the full training, PEFT (https://github.com/huggingface/peft) is considered.  \n",
        "RoBERTa supports LoRa, Prefix Tuning, P-Tuning and Prompt Tuning: https://github.com/huggingface/peft#sequence-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation of fully trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sentiment Prediction with selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rK7BZAfyx_rY"
      },
      "source": [
        "## 8. Compare internal vs. external"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
