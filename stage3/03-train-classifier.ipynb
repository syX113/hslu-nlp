{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"UyvrKk4ZBcNI"},"source":["# CLT Project - Stage III\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fzpbTSOZBcNP"},"source":["- **Author:**             Arian Contessotto, Tim Giger, Levin Reichmuth\n","- **Submission Date:**    1 June 2023"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZHGNKKFbBcNR"},"source":["## 1. Prerequisites and Load"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ATGDdAK4NloL"},"source":["If necessary, install the required packages."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17392,"status":"ok","timestamp":1684616408821,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"cBNiqJjdBcNT","outputId":"ee77655a-2a1d-4432-e66a-9c8e395f4150"},"outputs":[],"source":["# Required package installation\n","!pip install transformers\n","!pip install torch"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ppL6jWrIBcNV"},"source":["### 1.1 Import Packages and Make Downloads"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mikPBmLaBcNV"},"outputs":[],"source":["# Imports\n","import torch\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from transformers import TrainingArguments, Trainer\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import EarlyStoppingCallback\n","from sklearn.metrics import accuracy_score,  mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.tensorboard import SummaryWriter\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TsgyJBEWBcNW"},"source":["### 1.2 Load Annotated Data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zzhuW_gcN404"},"source":["The final dataframe from stage one is loaded. These data are the basis for stage two."]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":12086,"status":"ok","timestamp":1684616431797,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"xzPR79XdBcNX","outputId":"152cf475-c764-4a77-e5de-428b8944d128"},"outputs":[{"name":"stdout","output_type":"stream","text":["(11071, 17)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company</th>\n","      <th>datatype</th>\n","      <th>title</th>\n","      <th>date</th>\n","      <th>domain</th>\n","      <th>esg_topics</th>\n","      <th>internal</th>\n","      <th>symbol</th>\n","      <th>sentence_tokens</th>\n","      <th>market_cap_in_usd_b</th>\n","      <th>sector</th>\n","      <th>industry</th>\n","      <th>year_month</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>sentiment_llm_continuous</th>\n","      <th>sentiment_llm_categorial</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Beiersdorf</td>\n","      <td>sustainability_report</td>\n","      <td>BeiersdorfAG Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[CleanWater, GHGEmission, ProductLiability, Va...</td>\n","      <td>1</td>\n","      <td>BEI</td>\n","      <td>[brands strategy sustainability agenda care be...</td>\n","      <td>25.99</td>\n","      <td>Consumer Staples</td>\n","      <td>Household &amp; Personal Products</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.4510161280632019, 0.6138720512390137, 0.226...</td>\n","      <td>[0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Deutsche Telekom</td>\n","      <td>sustainability_report</td>\n","      <td>DeutscheTelekomAG Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[DataSecurity, Iso50001, GlobalWarming, Produc...</td>\n","      <td>1</td>\n","      <td>DTE</td>\n","      <td>[management facts, deutsche telekom cr report,...</td>\n","      <td>101.78</td>\n","      <td>Communication Services</td>\n","      <td>Telecom Services</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.35756340622901917, 0.29088783264160156, 0.3...</td>\n","      <td>[0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vonovia</td>\n","      <td>sustainability_report</td>\n","      <td>VonoviaSE Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[Whistleblowing, DataSecurity, Vaccine, GHGEmi...</td>\n","      <td>1</td>\n","      <td>VNA</td>\n","      <td>[sustainable future, sustainability report dea...</td>\n","      <td>20.35</td>\n","      <td>Real Estate</td>\n","      <td>Real Estate Services</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.4570336639881134, 0.45287153124809265, 0.26...</td>\n","      <td>[0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Merck</td>\n","      <td>sustainability_report</td>\n","      <td>MerckKGaA Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[DataSecurity, DataMisuse, DrugResistance, Iso...</td>\n","      <td>1</td>\n","      <td>MRK</td>\n","      <td>[management employees profile attractive emplo...</td>\n","      <td>87.64</td>\n","      <td>Healthcare</td>\n","      <td>Drug Manufacturers—Specialty &amp; Generic</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.36378589272499084, 0.6118267178535461, 0.48...</td>\n","      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>MTU</td>\n","      <td>sustainability_report</td>\n","      <td>MTUAeroEngines Sustainability Report 2020</td>\n","      <td>2020-03-31</td>\n","      <td>NaN</td>\n","      <td>[WorkLifeBalance, Corruption, AirQuality, Data...</td>\n","      <td>1</td>\n","      <td>MTX</td>\n","      <td>[sustainability goes far beyond climate action...</td>\n","      <td>12.24</td>\n","      <td>Industrials</td>\n","      <td>Aerospace &amp; Defense</td>\n","      <td>2020-03</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>[0.46082836389541626, 0.46208637952804565, 0.4...</td>\n","      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            company               datatype  \\\n","0        Beiersdorf  sustainability_report   \n","1  Deutsche Telekom  sustainability_report   \n","2           Vonovia  sustainability_report   \n","3             Merck  sustainability_report   \n","4               MTU  sustainability_report   \n","\n","                                          title        date domain  \\\n","0       BeiersdorfAG Sustainability Report 2021  2021-03-31    NaN   \n","1  DeutscheTelekomAG Sustainability Report 2021  2021-03-31    NaN   \n","2          VonoviaSE Sustainability Report 2021  2021-03-31    NaN   \n","3          MerckKGaA Sustainability Report 2021  2021-03-31    NaN   \n","4     MTUAeroEngines Sustainability Report 2020  2020-03-31    NaN   \n","\n","                                          esg_topics  internal symbol  \\\n","0  [CleanWater, GHGEmission, ProductLiability, Va...         1    BEI   \n","1  [DataSecurity, Iso50001, GlobalWarming, Produc...         1    DTE   \n","2  [Whistleblowing, DataSecurity, Vaccine, GHGEmi...         1    VNA   \n","3  [DataSecurity, DataMisuse, DrugResistance, Iso...         1    MRK   \n","4  [WorkLifeBalance, Corruption, AirQuality, Data...         1    MTX   \n","\n","                                     sentence_tokens  market_cap_in_usd_b  \\\n","0  [brands strategy sustainability agenda care be...                25.99   \n","1  [management facts, deutsche telekom cr report,...               101.78   \n","2  [sustainable future, sustainability report dea...                20.35   \n","3  [management employees profile attractive emplo...                87.64   \n","4  [sustainability goes far beyond climate action...                12.24   \n","\n","                   sector                                industry year_month  \\\n","0        Consumer Staples           Household & Personal Products    2021-03   \n","1  Communication Services                        Telecom Services    2021-03   \n","2             Real Estate                    Real Estate Services    2021-03   \n","3              Healthcare  Drug Manufacturers—Specialty & Generic    2021-03   \n","4             Industrials                     Aerospace & Defense    2020-03   \n","\n","   year  month                           sentiment_llm_continuous  \\\n","0  2021      3  [0.4510161280632019, 0.6138720512390137, 0.226...   \n","1  2021      3  [0.35756340622901917, 0.29088783264160156, 0.3...   \n","2  2021      3  [0.4570336639881134, 0.45287153124809265, 0.26...   \n","3  2021      3  [0.36378589272499084, 0.6118267178535461, 0.48...   \n","4  2020      3  [0.46082836389541626, 0.46208637952804565, 0.4...   \n","\n","                            sentiment_llm_categorial  \n","0  [0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...  \n","1  [0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...  \n","2  [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...  \n","3  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...  \n","4  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...  "]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# Define file name\n","esg_file = '../stage2/annotated/full_llm_annotated.csv'\n","\n","# Define function to load and merge data\n","def load_data(file):\n","\n","    # Load the data\n","    df = pd.read_csv(file, delimiter = '|')\n","\n","    # Apply eval function\n","    df['esg_topics'] = df['esg_topics'].apply(eval)\n","    df['sentence_tokens'] = df['sentence_tokens'].apply(eval)\n","    df['sentiment_llm_continuous'] = df['sentiment_llm_continuous'].apply(eval)\n","    df['sentiment_llm_categorial'] = df['sentiment_llm_categorial'].apply(eval)\n","\n","    return df\n","\n","df = load_data(esg_file)\n","\n","# Print shape and diyplay header\n","print(df.shape)\n","df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1.3 Create different Dataframes (Sentences & full Document)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"4IEirqQJmfLm"},"outputs":[{"name":"stdout","output_type":"stream","text":["(110, 17)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company</th>\n","      <th>datatype</th>\n","      <th>title</th>\n","      <th>date</th>\n","      <th>domain</th>\n","      <th>esg_topics</th>\n","      <th>internal</th>\n","      <th>symbol</th>\n","      <th>sentence_tokens</th>\n","      <th>market_cap_in_usd_b</th>\n","      <th>sector</th>\n","      <th>industry</th>\n","      <th>year_month</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>sentiment_llm_continuous</th>\n","      <th>sentiment_llm_categorial</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Beiersdorf</td>\n","      <td>sustainability_report</td>\n","      <td>BeiersdorfAG Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[CleanWater, GHGEmission, ProductLiability, Va...</td>\n","      <td>1</td>\n","      <td>BEI</td>\n","      <td>[brands strategy sustainability agenda care be...</td>\n","      <td>25.99</td>\n","      <td>Consumer Staples</td>\n","      <td>Household &amp; Personal Products</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.4510161280632019, 0.6138720512390137, 0.226...</td>\n","      <td>[0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Deutsche Telekom</td>\n","      <td>sustainability_report</td>\n","      <td>DeutscheTelekomAG Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[DataSecurity, Iso50001, GlobalWarming, Produc...</td>\n","      <td>1</td>\n","      <td>DTE</td>\n","      <td>[management facts, deutsche telekom cr report,...</td>\n","      <td>101.78</td>\n","      <td>Communication Services</td>\n","      <td>Telecom Services</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.35756340622901917, 0.29088783264160156, 0.3...</td>\n","      <td>[0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vonovia</td>\n","      <td>sustainability_report</td>\n","      <td>VonoviaSE Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[Whistleblowing, DataSecurity, Vaccine, GHGEmi...</td>\n","      <td>1</td>\n","      <td>VNA</td>\n","      <td>[sustainable future, sustainability report dea...</td>\n","      <td>20.35</td>\n","      <td>Real Estate</td>\n","      <td>Real Estate Services</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.4570336639881134, 0.45287153124809265, 0.26...</td>\n","      <td>[0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Merck</td>\n","      <td>sustainability_report</td>\n","      <td>MerckKGaA Sustainability Report 2021</td>\n","      <td>2021-03-31</td>\n","      <td>NaN</td>\n","      <td>[DataSecurity, DataMisuse, DrugResistance, Iso...</td>\n","      <td>1</td>\n","      <td>MRK</td>\n","      <td>[management employees profile attractive emplo...</td>\n","      <td>87.64</td>\n","      <td>Healthcare</td>\n","      <td>Drug Manufacturers—Specialty &amp; Generic</td>\n","      <td>2021-03</td>\n","      <td>2021</td>\n","      <td>3</td>\n","      <td>[0.36378589272499084, 0.6118267178535461, 0.48...</td>\n","      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>MTU</td>\n","      <td>sustainability_report</td>\n","      <td>MTUAeroEngines Sustainability Report 2020</td>\n","      <td>2020-03-31</td>\n","      <td>NaN</td>\n","      <td>[WorkLifeBalance, Corruption, AirQuality, Data...</td>\n","      <td>1</td>\n","      <td>MTX</td>\n","      <td>[sustainability goes far beyond climate action...</td>\n","      <td>12.24</td>\n","      <td>Industrials</td>\n","      <td>Aerospace &amp; Defense</td>\n","      <td>2020-03</td>\n","      <td>2020</td>\n","      <td>3</td>\n","      <td>[0.46082836389541626, 0.46208637952804565, 0.4...</td>\n","      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            company               datatype  \\\n","0        Beiersdorf  sustainability_report   \n","1  Deutsche Telekom  sustainability_report   \n","2           Vonovia  sustainability_report   \n","3             Merck  sustainability_report   \n","4               MTU  sustainability_report   \n","\n","                                          title        date domain  \\\n","0       BeiersdorfAG Sustainability Report 2021  2021-03-31    NaN   \n","1  DeutscheTelekomAG Sustainability Report 2021  2021-03-31    NaN   \n","2          VonoviaSE Sustainability Report 2021  2021-03-31    NaN   \n","3          MerckKGaA Sustainability Report 2021  2021-03-31    NaN   \n","4     MTUAeroEngines Sustainability Report 2020  2020-03-31    NaN   \n","\n","                                          esg_topics  internal symbol  \\\n","0  [CleanWater, GHGEmission, ProductLiability, Va...         1    BEI   \n","1  [DataSecurity, Iso50001, GlobalWarming, Produc...         1    DTE   \n","2  [Whistleblowing, DataSecurity, Vaccine, GHGEmi...         1    VNA   \n","3  [DataSecurity, DataMisuse, DrugResistance, Iso...         1    MRK   \n","4  [WorkLifeBalance, Corruption, AirQuality, Data...         1    MTX   \n","\n","                                     sentence_tokens  market_cap_in_usd_b  \\\n","0  [brands strategy sustainability agenda care be...                25.99   \n","1  [management facts, deutsche telekom cr report,...               101.78   \n","2  [sustainable future, sustainability report dea...                20.35   \n","3  [management employees profile attractive emplo...                87.64   \n","4  [sustainability goes far beyond climate action...                12.24   \n","\n","                   sector                                industry year_month  \\\n","0        Consumer Staples           Household & Personal Products    2021-03   \n","1  Communication Services                        Telecom Services    2021-03   \n","2             Real Estate                    Real Estate Services    2021-03   \n","3              Healthcare  Drug Manufacturers—Specialty & Generic    2021-03   \n","4             Industrials                     Aerospace & Defense    2020-03   \n","\n","   year  month                           sentiment_llm_continuous  \\\n","0  2021      3  [0.4510161280632019, 0.6138720512390137, 0.226...   \n","1  2021      3  [0.35756340622901917, 0.29088783264160156, 0.3...   \n","2  2021      3  [0.4570336639881134, 0.45287153124809265, 0.26...   \n","3  2021      3  [0.36378589272499084, 0.6118267178535461, 0.48...   \n","4  2020      3  [0.46082836389541626, 0.46208637952804565, 0.4...   \n","\n","                            sentiment_llm_categorial  \n","0  [0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...  \n","1  [0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, ...  \n","2  [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...  \n","3  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...  \n","4  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Function to create Subset to test code\n","def create_subset(df):\n","    \n","    # Select 10 rows with internal value of 1\n","    subset_1 = df[df['internal'] == 1].head(10)\n","\n","    # Select 100 rows with internal value of 0\n","    subset_0 = df[df['internal'] == 0].head(100)\n","\n","    # Concatenate the two subsets and reset the index\n","    subset = pd.concat([subset_1, subset_0])\n","    subset = subset.reset_index(drop=True)\n","\n","    return subset\n","\n","# Create subset\n","subset_df = create_subset(df)\n","\n","# Display header and shape\n","print(subset_df.shape)\n","subset_df.head()"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1684616431799,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"kas2z-8wsNbe","outputId":"e4290aac-f9d9-4c00-9963-2076ea05fbdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["(678529, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>brands strategy sustainability agenda care bey...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>successfully reduced carbon footprint absolute...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>end consumer business returned levels reduced ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>decoupling human economic activity natural res...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>inspired beiersdorf ambitious sustainability a...</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  sentiment\n","0  brands strategy sustainability agenda care bey...        0.5\n","1  successfully reduced carbon footprint absolute...        0.5\n","2  end consumer business returned levels reduced ...        0.0\n","3  decoupling human economic activity natural res...        0.0\n","4  inspired beiersdorf ambitious sustainability a...        0.5"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# Function to create sentence dataset\n","def create_sentence_df(data):\n","  \n","  # Get sentences and sentiments from data\n","  sentence_lists = data['sentence_tokens'].tolist()\n","  sentences = [sentence for sublist in sentence_lists for sentence in sublist]\n","  sentiment_list = data['sentiment_llm_categorial'].tolist()\n","  sentiment = [sentiment for sublist in sentiment_list for sentiment in sublist]\n","\n","  # Create pandas dataframe\n","  df = {'sentence': sentences, 'sentiment': sentiment}\n","  sentence_df = pd.DataFrame(df)\n","\n","  return sentence_df\n","\n","# Create sentence data\n","sentence_df = create_sentence_df(df)\n","\n","# Display header and shape\n","print(sentence_df.shape)\n","sentence_df.head()"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(11071, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>brands strategy sustainability agenda care bey...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>management facts deutsche telekom cr report th...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sustainable future sustainability report dear ...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>management employees profile attractive employ...</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sustainability goes far beyond climate action ...</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  sentiment\n","0  brands strategy sustainability agenda care bey...        0.5\n","1  management facts deutsche telekom cr report th...        0.5\n","2  sustainable future sustainability report dear ...        0.5\n","3  management employees profile attractive employ...        0.5\n","4  sustainability goes far beyond climate action ...        0.5"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Function to create document data\n","def create_document_df(data):\n","\n","    # Ensure sentence_tokens and sentiment_llm_continuous are in the correct list format\n","    data['document'] = data['sentence_tokens']\n","\n","    # Compute the mean of the computed sentiment and discretize it\n","    def discretize_sentiment(value):\n","        if value <= 0.33:\n","            return 0.0\n","        elif value <= 0.66:\n","            return 0.5\n","        else:\n","            return 1.0\n","\n","    data['sentiment'] = data['sentiment_llm_continuous'].apply(np.mean).apply(discretize_sentiment)\n","    \n","    # Return only the \"sentence_tokens\" and discretized mean of the sentiment\n","    return data[['document', 'sentiment']]\n","\n","# Create sentence data\n","document_df = create_document_df(df)\n","\n","# Display header and shape\n","print(document_df.shape)\n","document_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As a result, the models can be trained and tested with 2 approaches:  \n","- A dataframe containing the full document and a discretized mean sentiment of all included sentences\n","- A dataframe containing each sentence with the corresponding discretized sentiment  \n","\n","\"Discretized\" corresponds to the labels 0.0 (negative), 0.5 (neutral) and 1.0 (positive)."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model Training"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As a first test, we use the lightweight \"distilbert-base-uncased\" model and fine-tune it on the full documents and the sentences.  \n","Since BERT only accepts 512 input word tokens, the full documents are heavyily truncated."]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'vocab_projector.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'vocab_layer_norm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Define pretrained tokenizer and model\n","model_name = \"distilbert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1) # 1 label to get a continuous score between 0 and 1"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Approch 1: Train on the truncated (full) documents"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n","X = list(document_df[\"document\"])\n","y = list(document_df[\"sentiment\"])\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n","\n","# Tokenize the datasets\n","X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["# Create the torch dataset to use dataset in PyTorch and override necessary methods\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","# Create the train, validation and test dataset as PyTorch datasets\n","train_dataset = Dataset(X_train_tokenized, y_train)\n","val_dataset = Dataset(X_val_tokenized, y_val)\n","test_dataset = Dataset(X_test_tokenized, y_test)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["# Functio to compute the comparison metrics\n","def compute_metrics(p):\n","    pred, labels = p\n","    \n","    # Use the appropriate metrics, since we don't have discrete classes but a continous score \n","    mse = mean_squared_error(y_true=labels, y_pred=pred)\n","    mae = mean_absolute_error(y_true=labels, y_pred=pred)\n","    r2 = r2_score(y_true=labels, y_pred=pred)\n","\n","    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["# Define training arguments\n","args = TrainingArguments(\n","    output_dir=\"./full_documents\",\n","    evaluation_strategy=\"steps\",\n","    eval_steps=10,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    gradient_accumulation_steps=4,\n","    seed=0,\n","    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n","    learning_rate=2e-5,\n","    logging_steps=10,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    report_to='tensorboard'\n",")\n","\n","# Define Huggingface Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",")"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["# Load Tensorboard\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["# Kill potential Tensorboard process, so it don't block the port\n","!pkill -f \"tensorboard\""]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-e3e70682c2094cac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-e3e70682c2094cac\");\n","          const url = new URL(\"http://localhost\");\n","          const port = 6010;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Start Tensorboard to monitor training process\n","%tensorboard --logdir ./ --port 6010"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.00 GiB total capacity; 9.20 GiB already allocated; 0 bytes free; 9.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[120], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train pre-trained model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1667\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1928\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1929\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1934\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:2699\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_cuda_amp \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_cpu_amp:\n\u001b[1;32m   2696\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_greater_or_equal_than_1_10:\n\u001b[1;32m   2697\u001b[0m         ctx_manager \u001b[39m=\u001b[39m (\n\u001b[1;32m   2698\u001b[0m             torch\u001b[39m.\u001b[39mcpu\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(cache_enabled\u001b[39m=\u001b[39mcache_enabled, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamp_dtype)\n\u001b[0;32m-> 2699\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_cpu_amp\n\u001b[1;32m   2700\u001b[0m             \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(cache_enabled\u001b[39m=\u001b[39mcache_enabled, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamp_dtype)\n\u001b[1;32m   2701\u001b[0m         )\n\u001b[1;32m   2702\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2703\u001b[0m         ctx_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast()\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/trainer.py:2731\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_inputs(inputs)\n\u001b[1;32m   2730\u001b[0m \u001b[39mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m-> 2731\u001b[0m     loss_mb \u001b[39m=\u001b[39m smp_forward_backward(model, inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps)\n\u001b[1;32m   2732\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2734\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1563\u001b[0m     input_ids,\n\u001b[1;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1572\u001b[0m )\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/miniconda3/envs/venv-hslu-nlp/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:230\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    227\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[1;32m    231\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    233\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.00 GiB total capacity; 9.20 GiB already allocated; 0 bytes free; 9.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# Delete cache and train pre-trained model\n","torch.cuda.empty_cache()\n","trainer.train()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Approch 2: Train on single sentences"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n","X = list(sentence_df[\"sentence\"])\n","y = list(sentence_df[\"sentiment\"])\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n","\n","# Tokenize the datasets\n","X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Again, create the Torch datasets\n","train_dataset = Dataset(X_train_tokenized, y_train)\n","val_dataset = Dataset(X_val_tokenized, y_val)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# Define training arguments\n","args = TrainingArguments(\n","    output_dir=\"./single_sentences\", # To store logs seperately\n","    evaluation_strategy=\"steps\",\n","    eval_steps=10,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    gradient_accumulation_steps=4,\n","    seed=0,\n","    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n","    learning_rate=2e-5,\n","    logging_steps=10,\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    report_to='tensorboard'\n",")\n","\n","# Define Huggingface Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Kill potential Tensorboard process, so it don't block the port\n","!pkill -f \"tensorboard\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Monitor training\n","%tensorboard --logdir ./ --port 6010"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Delete cache and train pre-trained model\n","torch.cuda.empty_cache()\n","trainer.train()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Compare the models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create torch dataset\n","test_dataset = Dataset(X_test_tokenized)\n","\n","# Load trained model\n","model_path =\"TBD\"\n","model = BertForSequenceClassification.from_pretrained(model_path, num_labels=1)\n","\n","# Define test trainer\n","test_trainer = Trainer(model)\n","\n","# Make predictions\n","predictions = test_trainer.predict(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9UZ_caPYX3jC"},"source":["## Train, Dev, Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Nw2PKk89psR"},"outputs":[],"source":["# Split the DataFrame into train, dev, and test sets (70%, 15% and 15%)\n","train_df, temp_df = train_test_split(sentence_df, test_size=0.3, random_state=42)\n","dev_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NIwomxvRY2Vm"},"source":["## Tokenize Sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBKy8NGC9pv6"},"outputs":[],"source":["# Define the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Tokenize the sentences and convert them to input features\n","def tokenize_sentences(sentences):\n","    input_ids = []\n","    attention_masks = []\n","    \n","    for sentence in sentences:\n","        encoded_dict = tokenizer.encode_plus(\n","            sentence,\n","            add_special_tokens=True,\n","            max_length=100,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        \n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","    \n","    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n","\n","# Tokenize the sentences in the train, dev, and test sets\n","train_sentences = train_df['sentence'].tolist()\n","dev_sentences = dev_df['sentence'].tolist()\n","test_sentences = test_df['sentence'].tolist()\n","train_inputs, train_masks = tokenize_sentences(train_sentences)\n","dev_inputs, dev_masks = tokenize_sentences(dev_sentences)\n","test_inputs, test_masks = tokenize_sentences(test_sentences)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lmwbJNB9Y6je"},"source":["## Convert sentiment scores to tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Osu0DVQk9py-"},"outputs":[],"source":["# Convert the sentiment scores to tensors\n","train_labels = torch.tensor(train_df['sentiment'].tolist())\n","dev_labels = torch.tensor(dev_df['sentiment'].tolist())\n","test_labels = torch.tensor(test_df['sentiment'].tolist())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVN5NUY9Y98g"},"source":["## Create DataLoader and Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0z7gXieYrUr"},"outputs":[],"source":["# Create a DataLoader for each set\n","batch_size = 64\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AF38wZp4ZFNG"},"source":["## Train base model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7488,"status":"ok","timestamp":1684616450246,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"5X_FceeT4Gtk","outputId":"5d860024-8d13-4547-dff1-cc57b81d65ae"},"outputs":[],"source":["# Load the pre-trained BERT model for sequence classification\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","\n","# Set the device (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","print(f'\\n Selected device to run: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Small evaluation function\n","def evaluate(model, dataloader):\n","    model.eval()\n","\n","    total_loss = 0\n","    total_accuracy = 0\n","\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, masks, labels = batch\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, attention_mask=masks, labels=labels)\n","\n","        loss = outputs.loss\n","        logits = outputs.logits\n","\n","        total_loss += loss.item()\n","\n","        # Calculate the accuracy for this batch\n","        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n","        true_labels = labels.cpu().numpy()\n","        accuracy = accuracy_score(true_labels, predictions)\n","        total_accuracy += accuracy\n","\n","    avg_loss = total_loss / len(dataloader)\n","    avg_accuracy = total_accuracy / len(dataloader)\n","\n","    return avg_loss, avg_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set the optimizer and parameter\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","num_epochs = 2\n","\n","# Create the SummaryWriter\n","writer = SummaryWriter()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for step, batch in enumerate(train_dataloader):        \n","\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, masks, labels = batch\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs, attention_mask=masks, labels=labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f'Epoch: {epoch+1}, Step: {step+1}, Loss: {loss.item()}')\n","\n","        # Log the loss and learning rate to TensorBoard\n","        writer.add_scalar(\"Loss/train\", loss, step)\n","        for param_group in optimizer.param_groups:\n","            writer.add_scalar(\"Learning rate\", param_group['lr'], step)\n","\n","        # Log histograms of all model parameters\n","        for name, param in model.named_parameters():\n","            if param.requires_grad:\n","                writer.add_histogram(name, param.data, step)\n","       \n","\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    writer.add_scalar(\"Average Loss/train\", avg_train_loss, epoch)\n","\n","    # Evaluate on the validation set and log metrics to TensorBoard\n","    avg_val_loss, avg_val_accuracy = evaluate(model, dev_dataloader)\n","    writer.add_scalar(\"Average Loss/validation\", avg_val_loss, epoch)\n","    writer.add_scalar(\"Average Accuracy/validation\", avg_val_accuracy, epoch)\n","\n","# After training\n","trained_model = model\n","writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%tensorboard  --logdir=runs --port=6007"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1684616538124,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"7hIe_QOR5eJw","outputId":"9fcd6c4d-4e30-4420-a0f0-17ba8745fcdb"},"outputs":[],"source":["print(trained_model)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BKZ-EEVYHSMA"},"source":["## Evaluate base model on dev set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6169,"status":"ok","timestamp":1684616544273,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"KHzx5Juv6Cek","outputId":"804b1341-28e1-48c2-fed4-c3576e1077e6"},"outputs":[],"source":["# Evaluation on the dev set\n","trained_model.eval()\n","dev_predictions = []\n","\n","with torch.no_grad():\n","    for batch in dev_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, masks, labels = batch\n","\n","        outputs = trained_model(inputs, attention_mask=masks)\n","        logits = outputs.logits\n","\n","        predictions = torch.sigmoid(logits).squeeze().tolist()\n","        dev_predictions.extend(predictions)\n","\n","    # Handle the remaining instances\n","    if len(dev_predictions) < len(dev_labels):\n","        remaining_instances = len(dev_labels) - len(dev_predictions)\n","        last_batch_inputs = dev_inputs[-remaining_instances:]\n","        last_batch_masks = dev_masks[-remaining_instances:]\n","        last_batch = (last_batch_inputs, last_batch_masks)\n","\n","        last_batch = tuple(t.to(device) for t in last_batch)\n","\n","        outputs = trained_model(*last_batch, attention_mask=last_batch[1])\n","        logits = outputs.logits\n","\n","        predictions = torch.sigmoid(logits).squeeze().tolist()\n","        dev_predictions.extend(predictions)\n","\n","# Calculate evaluation metrics\n","# Define the thresholds for discretization\n","thresholds = [1/3, 2/3]\n","\n","# Discretize the predicted probabilities\n","discretized_predictions = np.digitize(dev_predictions, thresholds)\n","\n","# Convert continuous labels to integers\n","dev_labels_int = np.digitize(dev_labels, thresholds)\n","\n","# Create the confusion matrix-like representation\n","num_classes = len(thresholds) + 1  # Number of classes: below threshold, between thresholds, above threshold\n","cm = np.zeros((num_classes, num_classes))\n","\n","for true_label, predicted_label in zip(dev_labels_int, discretized_predictions):\n","    cm[true_label, predicted_label] += 1\n","\n","# Print the confusion matrix-like representation\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","# Get the values from the confusion matrix\n","TP = cm[1, 1]\n","FP = cm[0, 1] + cm[2, 1]\n","FN = cm[1, 0] + cm[1, 2]\n","TN = cm[0, 0] + cm[0, 2] + cm[2, 0] + cm[2, 2]\n","\n","# Compute accuracy\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","\n","# Compute precision\n","precision = TP / (TP + FP)\n","\n","# Compute recall\n","recall = TP / (TP + FN)\n","\n","# Print the metrics\n","print(f\"Accuracy:\", accuracy)\n","print(f\"Precision:\", precision)\n","print(f\"Recall:\", recall)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MbEvy82OHW1B"},"source":["## Parameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566516,"status":"ok","timestamp":1684617110773,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"xVOT0rJt6CGi","outputId":"e7f8d100-8659-4289-a36c-4092810a7f81"},"outputs":[],"source":["# Define list of parameters\n","batch_sizes = [16]\n","learning_rates = [5e-5, 1e-5]\n","num_epochs_list = [1, 2]\n","\n","# Set results dict\n","results = {\n","    'batch_size': [],\n","    'learning_rate': [],\n","    'num_epochs': [],\n","    'accuracy': [],\n","    'precision': [],\n","    'recall': [],\n","    'confusion_matrix': []\n","}\n","\n","# Iterate over parameter combinations\n","for batch_size in batch_sizes:\n","    for learning_rate in learning_rates:\n","        for num_epochs in num_epochs_list:\n","            # Train the model with the current hyperparameters\n","           \n","            # Load the pre-trained BERT model for sequence classification\n","            model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","\n","            # Set the device (GPU if available, else CPU)\n","            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","            print(device)\n","            model = model.to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","            train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","            for epoch in range(num_epochs):\n","                model.train()\n","                for batch in train_dataloader:\n","                    batch = tuple(t.to(device) for t in batch)\n","                    inputs, masks, labels = batch\n","                    \n","                    optimizer.zero_grad()\n","                    # Forward pass\n","                    outputs = model(inputs, attention_mask=masks, labels=labels)\n","                    loss = outputs.loss\n","                    logits = outputs.logits\n","                    \n","                    # Backward pass and optimization\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            # Evaluation on dev set\n","            model.eval()\n","            dev_predictions = []\n","\n","            with torch.no_grad():\n","                for batch in dev_dataloader:\n","                    batch = tuple(t.to(device) for t in batch)\n","                    inputs, masks, labels = batch\n","\n","                    outputs = trained_model(inputs, attention_mask=masks)\n","                    logits = outputs.logits\n","\n","                    predictions = torch.sigmoid(logits).squeeze().tolist()\n","                    dev_predictions.extend(predictions)\n","\n","                # Handle the remaining instances\n","                if len(dev_predictions) < len(dev_labels):\n","                    remaining_instances = len(dev_labels) - len(dev_predictions)\n","                    last_batch_inputs = dev_inputs[-remaining_instances:]\n","                    last_batch_masks = dev_masks[-remaining_instances:]\n","                    last_batch = (last_batch_inputs, last_batch_masks)\n","\n","                    last_batch = tuple(t.to(device) for t in last_batch)\n","\n","                    outputs = trained_model(*last_batch, attention_mask=last_batch[1])\n","                    logits = outputs.logits\n","\n","                    predictions = torch.sigmoid(logits).squeeze().tolist()\n","                    dev_predictions.extend(predictions)\n","\n","            # Calculate evaluation metrics\n","            # Define the thresholds for discretization\n","            thresholds = [1/3, 2/3]\n","\n","            # Discretize the predicted probabilities\n","            discretized_predictions = np.digitize(dev_predictions, thresholds)\n","\n","            # Convert continuous labels to integers\n","            dev_labels_int = np.digitize(dev_labels, thresholds)\n","\n","            # Create the confusion matrix-like representation\n","            num_classes = len(thresholds) + 1  # Number of classes: below threshold, between thresholds, above threshold\n","            cm = np.zeros((num_classes, num_classes))\n","\n","            for true_label, predicted_label in zip(dev_labels_int, discretized_predictions):\n","                cm[true_label, predicted_label] += 1\n","\n","            # Print the confusion matrix-like representation\n","            print(\"Confusion Matrix:\")\n","            print(cm)\n","\n","            # Get the values from the confusion matrix\n","            TP = cm[1, 1]\n","            FP = cm[0, 1] + cm[2, 1]\n","            FN = cm[1, 0] + cm[1, 2]\n","            TN = cm[0, 0] + cm[0, 2] + cm[2, 0] + cm[2, 2]\n","\n","            # Compute accuracy\n","            accuracy = (TP + TN) / (TP + TN + FP + FN)\n","\n","            # Compute precision\n","            precision = TP / (TP + FP)\n","\n","            # Compute recall\n","            recall = TP / (TP + FN)\n","\n","            # Store the results in the dictionary\n","            results['batch_size'].append(batch_size)\n","            results['learning_rate'].append(learning_rate)\n","            results['num_epochs'].append(num_epochs)\n","            results['accuracy'].append(accuracy)\n","            results['precision'].append(precision)\n","            results['recall'].append(recall)\n","            results['confusion_matrix'].append(cm)\n","\n","# Create results df out of results dictionary\n","results_df = pd.DataFrame(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1684617110775,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"mj2tCoW1UONv","outputId":"c0e611ac-0e4a-4e14-d28f-1e1202142492"},"outputs":[],"source":["# Display results dataframe\n","results_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1684617111939,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"w5B7qsOqWl7b","outputId":"2bddbe2e-d3c8-4123-fa83-582b78488aa2"},"outputs":[],"source":["# Create subplots for each metric\n","fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n","metrics = ['accuracy', 'precision', 'recall']\n","num_epochs = results_df['num_epochs'].unique().tolist()\n","\n","for i, metric in enumerate(metrics):\n","    ax = axes[i // 2, i % 2]\n","    \n","    # Group the dataframe by batch_size and learning_rate\n","    grouped_df = results_df.groupby(['batch_size', 'learning_rate'])\n","    \n","    # Iterate over the unique combinations\n","    for (bs, lr), group in grouped_df:\n","        # Get the metric values for the current combination\n","        metric_values = group[metric].values\n","        \n","        # Plot the metric values as a line\n","        ax.plot(num_epochs, metric_values, marker='o', label=f\"Batch sizes={bs}, LR={lr}\")\n","\n","    ax.set_xticks(num_epochs)\n","    ax.set_xticklabels(num_epochs)\n","    ax.set_xlabel(\"Number of epochs\")\n","    ax.set_ylabel(metric.capitalize())\n","    ax.set_title(metric.capitalize())\n","    ax.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t5s0kz7fRb1u"},"source":["## Train final model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":865,"status":"ok","timestamp":1684617112798,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"JJERVi3zHY03","outputId":"c61a6f4d-1096-49db-9e7a-4a9ced5e9f67"},"outputs":[],"source":["# Load the pre-trained BERT model for sequence classification\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n","\n","# Set the device (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","model = model.to(device)\n","\n","# Set the optimizer and parameter\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","num_epochs = 3\n","batch_size = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263235,"status":"ok","timestamp":1684617376027,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"gKgkWEmmZX3_","outputId":"6e32eb23-f33e-4024-e724-f78d4dfe0568"},"outputs":[],"source":["train_loss_values = []  # List to store training loss values\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0.0  # Variable to accumulate the loss for each epoch\n","    \n","    for batch in train_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, masks, labels = batch\n","        \n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(inputs, attention_mask=masks, labels=labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        \n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()  # Accumulate the loss for the current batch\n","        \n","    # Calculate the average training loss for the epoch\n","    avg_epoch_loss = epoch_loss / len(train_dataloader)\n","    \n","    train_loss_values.append(avg_epoch_loss)  # Store the training loss value for the epoch\n","    \n","    # Print the training loss for the epoch\n","    print(f\"Epoch {epoch+1} - Training Loss: {avg_epoch_loss:.4f}\")\n","\n","# After training\n","final_model = model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1684617500584,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"c-c1raqeKG0M","outputId":"4b0c64ba-ca39-4e6e-e3ba-a8b06207b2d9"},"outputs":[],"source":["print(final_model)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2HgRBEyWRxBJ"},"source":["## Evaluate final model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6413,"status":"ok","timestamp":1684617519941,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"Eoo9jrMgKGuf","outputId":"9ced4fbe-c4bf-44de-f1dc-60940d42247e"},"outputs":[],"source":["# Evaluation on the test set\n","final_model.eval()\n","test_predictions = []\n","\n","with torch.no_grad():\n","    for batch in test_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs, masks, labels = batch\n","\n","        outputs = final_model(inputs, attention_mask=masks)\n","        logits = outputs.logits\n","\n","        predictions = torch.sigmoid(logits).squeeze().tolist()\n","        test_predictions.extend(predictions)\n","\n","    # Handle the remaining instances\n","    if len(test_predictions) < len(test_labels):\n","        remaining_instances = len(test_labels) - len(test_predictions)\n","        last_batch_inputs = test_inputs[-remaining_instances:]\n","        last_batch_masks = test_masks[-remaining_instances:]\n","        last_batch = (last_batch_inputs, last_batch_masks)\n","\n","        last_batch = tuple(t.to(device) for t in last_batch)\n","\n","        outputs = final_model(*last_batch, attention_mask=last_batch[1])\n","        logits = outputs.logits\n","\n","        predictions = torch.sigmoid(logits).squeeze().tolist()\n","        test_predictions.extend(predictions)\n","\n","# Calculate evaluation metrics\n","# Define the thresholds for discretization\n","thresholds = [1/3, 2/3]\n","\n","# Discretize the predicted probabilities\n","discretized_predictions = np.digitize(test_predictions, thresholds)\n","\n","# Convert continuous labels to integers\n","test_labels_int = np.digitize(test_labels, thresholds)\n","\n","# Create the confusion matrix-like representation\n","num_classes = len(thresholds) + 1  # Number of classes: below threshold, between thresholds, above threshold\n","cm = np.zeros((num_classes, num_classes))\n","\n","for true_label, predicted_label in zip(test_labels_int, discretized_predictions):\n","    cm[true_label, predicted_label] += 1\n","\n","# Print the confusion matrix-like representation\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","# Get the values from the confusion matrix\n","TP = cm[1, 1]\n","FP = cm[0, 1] + cm[2, 1]\n","FN = cm[1, 0] + cm[1, 2]\n","TN = cm[0, 0] + cm[0, 2] + cm[2, 0] + cm[2, 2]\n","\n","# Compute accuracy\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","\n","# Compute precision\n","precision = TP / (TP + FP)\n","\n","# Compute recall\n","recall = TP / (TP + FN)\n","\n","# Print the metrics\n","print(f\"Accuracy:\", accuracy)\n","print(f\"Precision:\", precision)\n","print(f\"Recall:\", recall)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rZAVy-vjSl-c"},"source":["## Annotate sentiments with final prediction model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":109108,"status":"ok","timestamp":1684617652399,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"p7Yd7jyUcBH5","outputId":"5f9cce31-5a31-4756-fd02-4440543adfef"},"outputs":[],"source":["# Define the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Tokenize the sentences and convert them to input features\n","def tokenize_sentences(sentences):\n","    input_ids = []\n","    attention_masks = []\n","    \n","    for sentence in sentences:\n","        encoded_dict = tokenizer.encode_plus(\n","            sentence,\n","            add_special_tokens=True,\n","            max_length=100,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        \n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","    \n","    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n","\n","def make_predictions(tokenized_sentences):\n","  inputs, masks = tokenized_sentences\n","\n","  # Prepare the data for model input\n","  inputs = inputs.to(device)\n","  masks = masks.to(device)\n","\n","  # Evaluate the model on the dataframe\n","  final_model.eval()\n","  sentiment_predictions = []\n","\n","  with torch.no_grad():\n","      for i in range(len(inputs)):\n","          input_ids = inputs[i].unsqueeze(0)\n","          attention_mask = masks[i].unsqueeze(0)\n","          \n","          outputs = final_model(input_ids, attention_mask=attention_mask)\n","          logits = outputs.logits\n","          \n","          predictions = torch.sigmoid(logits).squeeze().tolist()\n","          sentiment_predictions.append(predictions)\n","  return sentiment_predictions\n","\n","subset_df['tokenized_sentences'] = subset_df['sentence_tokens'].apply(lambda x: tokenize_sentences(x))\n","subset_df['sentiments'] = subset_df['tokenized_sentences'].apply(lambda x: make_predictions(x))\n","subset_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rK7BZAfyx_rY"},"source":["## Compare internal vs. external"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2576,"status":"ok","timestamp":1684617676832,"user":{"displayName":"Arian Contessotto","userId":"11268796571837754697"},"user_tz":-120},"id":"SsYNhfC7qqSl","outputId":"13d49e4d-4375-482e-a584-0a033ec276e6"},"outputs":[],"source":["# Compute the average of each list in the 'sentiments' column\n","subset_df['sentiments_avg'] = subset_df['sentiments'].apply(lambda x: np.mean(x))\n","\n","# Create two separate dataframes for internal values 0 and 1\n","subset_internal_0 = subset_df[subset_df['internal'] == 0]\n","subset_internal_1 = subset_df[subset_df['internal'] == 1]\n","\n","# Create boxplots for average sentiments grouped by internal values\n","plt.figure(figsize=(8, 6))\n","sns.boxplot(x='internal', y='sentiments_avg', data=subset_df)\n","plt.xlabel('Internal')\n","plt.ylabel('Average Sentiments')\n","plt.title('Boxplot of Average Sentiments by Internal')\n","plt.show()\n","\n","# Create histograms for average sentiments grouped by internal values\n","plt.figure(figsize=(8, 6))\n","sns.histplot(data=subset_df, x='sentiments_avg', hue='internal', element='step', bins=10, alpha=0.5, legend=True)\n","plt.xlabel('Average Sentiments')\n","plt.ylabel('Frequency')\n","plt.title('Histogram of Average Sentiments by Internal')\n","plt.show()\n"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
