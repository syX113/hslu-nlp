{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UyvrKk4ZBcNI"
      },
      "source": [
        "# CLT Project - Stage III\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fzpbTSOZBcNP"
      },
      "source": [
        "- **Author:**             Arian Contessotto, Tim Giger, Levin Reichmuth\n",
        "- **Submission Date:**    1 June 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHGNKKFbBcNR"
      },
      "source": [
        "## 1. Setup & Data Loading"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ATGDdAK4NloL"
      },
      "source": [
        "If running on Colab, install the required packages and load data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMbz9g1GhM8h",
        "outputId": "f4ee390e-7a82-456f-a575-f8376cb53567"
      },
      "outputs": [],
      "source": [
        "# Clone repo with dataset\n",
        "!git clone https://github.com/syX113/hslu-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-su7FTvhjtW",
        "outputId": "c142039c-b845-4820-9950-76895875e69a"
      },
      "outputs": [],
      "source": [
        "# Check if files are loaded\n",
        "!ls hslu-nlp/stage2/annotated/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBNiqJjdBcNT",
        "outputId": "d19fa007-38e6-401f-ff62-375663f9d095"
      },
      "outputs": [],
      "source": [
        "# Required package installation\n",
        "!transformers==4.28.0\n",
        "!pip install torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ppL6jWrIBcNV"
      },
      "source": [
        "### 1.1 Import Packages & Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mikPBmLaBcNV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-28 13:38:37.295971: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-28 13:38:37.321868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-28 13:38:37.724534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "from transformers import XLNetTokenizerFast, XLNetForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhuW_gcN404"
      },
      "source": [
        "The final dataframe from stage one is loaded. These data are the basis for stage two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "xzPR79XdBcNX",
        "outputId": "2e5e8a18-6c4e-4b11-f648-e989ef8b0e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11072, 20)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>datatype</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>domain</th>\n",
              "      <th>cnt_word</th>\n",
              "      <th>cleaned_content</th>\n",
              "      <th>esg_topics</th>\n",
              "      <th>internal</th>\n",
              "      <th>symbol</th>\n",
              "      <th>sentence_tokens</th>\n",
              "      <th>market_cap_in_usd_b</th>\n",
              "      <th>sector</th>\n",
              "      <th>industry</th>\n",
              "      <th>year_month</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>st1_sentiment_continuous</th>\n",
              "      <th>st2_sentiment_llm_continuous</th>\n",
              "      <th>st2_sentiment_llm_categorical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beiersdorf</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>BeiersdorfAG Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4877</td>\n",
              "      <td>brand strategy sustainability agenda care beyo...</td>\n",
              "      <td>[CleanWater, GHGEmission, ProductLiability, Va...</td>\n",
              "      <td>1</td>\n",
              "      <td>BEI</td>\n",
              "      <td>[brands strategy sustainability agenda care be...</td>\n",
              "      <td>25.99</td>\n",
              "      <td>Consumer Staples</td>\n",
              "      <td>Household &amp; Personal Products</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>0.398557</td>\n",
              "      <td>[0.4510159492492676, 0.6138717532157898, 0.226...</td>\n",
              "      <td>[0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deutsche Telekom</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>DeutscheTelekomAG Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53913</td>\n",
              "      <td>management fact deutsche telekoms cr report th...</td>\n",
              "      <td>[DataSecurity, Iso50001, GlobalWarming, Produc...</td>\n",
              "      <td>1</td>\n",
              "      <td>DTE</td>\n",
              "      <td>[management facts, deutsche telekom cr report,...</td>\n",
              "      <td>101.78</td>\n",
              "      <td>Communication Services</td>\n",
              "      <td>Telecom Services</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>0.205642</td>\n",
              "      <td>[0.3575633764266968, 0.29088786244392395, 0.50...</td>\n",
              "      <td>[0.5, 0.0, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vonovia</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>VonoviaSE Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36707</td>\n",
              "      <td>sustainable future se sustainability report de...</td>\n",
              "      <td>[Whistleblowing, DataSecurity, Vaccine, GHGEmi...</td>\n",
              "      <td>1</td>\n",
              "      <td>VNA</td>\n",
              "      <td>[sustainable future, se sustainability report ...</td>\n",
              "      <td>20.35</td>\n",
              "      <td>Real Estate</td>\n",
              "      <td>Real Estate Services</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>0.242471</td>\n",
              "      <td>[0.45703375339508057, 0.38698673248291016, 0.2...</td>\n",
              "      <td>[0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Merck</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>MerckKGaA Sustainability Report 2021</td>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46497</td>\n",
              "      <td>management employee profile attractive employe...</td>\n",
              "      <td>[DataSecurity, DataMisuse, DrugResistance, Iso...</td>\n",
              "      <td>1</td>\n",
              "      <td>MRK</td>\n",
              "      <td>[management employees profile attractive emplo...</td>\n",
              "      <td>87.64</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>Drug Manufacturers—Specialty &amp; Generic</td>\n",
              "      <td>2021-03</td>\n",
              "      <td>2021</td>\n",
              "      <td>3</td>\n",
              "      <td>0.235490</td>\n",
              "      <td>[0.3637859523296356, 0.6118264198303223, 0.489...</td>\n",
              "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MTU</td>\n",
              "      <td>sustainability_report</td>\n",
              "      <td>MTUAeroEngines Sustainability Report 2020</td>\n",
              "      <td>2020-03-31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21571</td>\n",
              "      <td>sustainability go far beyond climate action sa...</td>\n",
              "      <td>[WorkLifeBalance, Corruption, AirQuality, Data...</td>\n",
              "      <td>1</td>\n",
              "      <td>MTX</td>\n",
              "      <td>[sustainability goes far beyond climate action...</td>\n",
              "      <td>12.24</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Aerospace &amp; Defense</td>\n",
              "      <td>2020-03</td>\n",
              "      <td>2020</td>\n",
              "      <td>3</td>\n",
              "      <td>0.241814</td>\n",
              "      <td>[0.4608282744884491, 0.4620864689350128, 0.430...</td>\n",
              "      <td>[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            company               datatype  \\\n",
              "0        Beiersdorf  sustainability_report   \n",
              "1  Deutsche Telekom  sustainability_report   \n",
              "2           Vonovia  sustainability_report   \n",
              "3             Merck  sustainability_report   \n",
              "4               MTU  sustainability_report   \n",
              "\n",
              "                                          title        date domain  cnt_word  \\\n",
              "0       BeiersdorfAG Sustainability Report 2021  2021-03-31    NaN      4877   \n",
              "1  DeutscheTelekomAG Sustainability Report 2021  2021-03-31    NaN     53913   \n",
              "2          VonoviaSE Sustainability Report 2021  2021-03-31    NaN     36707   \n",
              "3          MerckKGaA Sustainability Report 2021  2021-03-31    NaN     46497   \n",
              "4     MTUAeroEngines Sustainability Report 2020  2020-03-31    NaN     21571   \n",
              "\n",
              "                                     cleaned_content  \\\n",
              "0  brand strategy sustainability agenda care beyo...   \n",
              "1  management fact deutsche telekoms cr report th...   \n",
              "2  sustainable future se sustainability report de...   \n",
              "3  management employee profile attractive employe...   \n",
              "4  sustainability go far beyond climate action sa...   \n",
              "\n",
              "                                          esg_topics  internal symbol  \\\n",
              "0  [CleanWater, GHGEmission, ProductLiability, Va...         1    BEI   \n",
              "1  [DataSecurity, Iso50001, GlobalWarming, Produc...         1    DTE   \n",
              "2  [Whistleblowing, DataSecurity, Vaccine, GHGEmi...         1    VNA   \n",
              "3  [DataSecurity, DataMisuse, DrugResistance, Iso...         1    MRK   \n",
              "4  [WorkLifeBalance, Corruption, AirQuality, Data...         1    MTX   \n",
              "\n",
              "                                     sentence_tokens  market_cap_in_usd_b  \\\n",
              "0  [brands strategy sustainability agenda care be...                25.99   \n",
              "1  [management facts, deutsche telekom cr report,...               101.78   \n",
              "2  [sustainable future, se sustainability report ...                20.35   \n",
              "3  [management employees profile attractive emplo...                87.64   \n",
              "4  [sustainability goes far beyond climate action...                12.24   \n",
              "\n",
              "                   sector                                industry year_month  \\\n",
              "0        Consumer Staples           Household & Personal Products    2021-03   \n",
              "1  Communication Services                        Telecom Services    2021-03   \n",
              "2             Real Estate                    Real Estate Services    2021-03   \n",
              "3              Healthcare  Drug Manufacturers—Specialty & Generic    2021-03   \n",
              "4             Industrials                     Aerospace & Defense    2020-03   \n",
              "\n",
              "   year  month  st1_sentiment_continuous  \\\n",
              "0  2021      3                  0.398557   \n",
              "1  2021      3                  0.205642   \n",
              "2  2021      3                  0.242471   \n",
              "3  2021      3                  0.235490   \n",
              "4  2020      3                  0.241814   \n",
              "\n",
              "                        st2_sentiment_llm_continuous  \\\n",
              "0  [0.4510159492492676, 0.6138717532157898, 0.226...   \n",
              "1  [0.3575633764266968, 0.29088786244392395, 0.50...   \n",
              "2  [0.45703375339508057, 0.38698673248291016, 0.2...   \n",
              "3  [0.3637859523296356, 0.6118264198303223, 0.489...   \n",
              "4  [0.4608282744884491, 0.4620864689350128, 0.430...   \n",
              "\n",
              "                       st2_sentiment_llm_categorical  \n",
              "0  [0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...  \n",
              "1  [0.5, 0.0, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, ...  \n",
              "2  [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, ...  \n",
              "3  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, ...  \n",
              "4  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, ...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define file name\n",
        "esg_file = '../stage2/output/stage2_output.csv' # Local filepath\n",
        "#esg_file = 'hslu-nlp/stage2/output/stage2_output.csv' # Filepath on Colab\n",
        "\n",
        "# Define function to load and merge data\n",
        "def load_data(file):\n",
        "\n",
        "    # Load the data\n",
        "    df = pd.read_csv(file, delimiter = '|')\n",
        "\n",
        "    # Apply eval function\n",
        "    df['esg_topics'] = df['esg_topics'].apply(eval)\n",
        "    df['sentence_tokens'] = df['sentence_tokens'].apply(eval)\n",
        "    df['st2_sentiment_llm_continuous'] = df['st2_sentiment_llm_continuous'].apply(eval)\n",
        "    df['st2_sentiment_llm_categorical'] = df['st2_sentiment_llm_categorical'].apply(eval)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data(esg_file)\n",
        "\n",
        "# Print shape and diyplay header\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flatten the continuous sentiments to analyze distribution and adjust class discretization to 0.0, 0.5 and 1.0\n",
        "flattened_sentiments_cont = np.hstack(df['st2_sentiment_llm_continuous'].values)\n",
        "flattened_sentiments_cat= np.hstack(df['st2_sentiment_llm_categorical'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create boxplot\n",
        "ax = sns.boxplot(x=flattened_sentiments_cont, showmeans=True,meanprops={\"marker\":\"x\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"black\", \"markersize\":\"5\"})\n",
        "\n",
        "# Calculate statistics\n",
        "median = np.median(flattened_sentiments_cont)\n",
        "mean = np.mean(flattened_sentiments_cont)\n",
        "q75, q25 = np.percentile(flattened_sentiments_cont, [75 ,25])\n",
        "iqr = q75 - q25\n",
        "\n",
        "# Add text with statistics\n",
        "plt.text(0.95, 0.95, f\"Median: {median:.4f}\", horizontalalignment='right', verticalalignment='top', transform=ax.transAxes)\n",
        "plt.text(0.95, 0.90, f\"Mean: {mean:.4f}\", horizontalalignment='right', verticalalignment='top', transform=ax.transAxes)\n",
        "plt.text(0.95, 0.85, f\"Q75: {q75:.4f}\", horizontalalignment='right', verticalalignment='top', transform=ax.transAxes)\n",
        "plt.text(0.95, 0.80, f\"Q25: {q25:.4f}\", horizontalalignment='right', verticalalignment='top', transform=ax.transAxes)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count the occurrences of each value\n",
        "value_counts = pd.Series(flattened_sentiments_cat).value_counts()\n",
        "# Create a bar plot with smaller bars\n",
        "plt.bar(value_counts.index, value_counts.values, color='blue', alpha=0.7, width=0.3)\n",
        "plt.title('Sentiment Bar Plot')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([0.0, 0.5, 1.0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to adjust the sentiment discretization\n",
        "def discretize_sentiment(value):\n",
        "    if value <= 0.35: # Mean of st2_sentiment_llm_continuous\n",
        "        return 0.0\n",
        "    elif value <= 0.43145: # Q75 of st2_sentiment_llm_continuous + a small shift\n",
        "        return 0.5\n",
        "    else:\n",
        "        return 1.0\n",
        "    \n",
        "def discretize_sentiments(sentiments):\n",
        "    if sentiments is np.nan:\n",
        "        return np.nan\n",
        "    return [discretize_sentiment(sentiment) for sentiment in sentiments]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['st2_sentiment_llm_categorical'] = df['st2_sentiment_llm_continuous'].apply(discretize_sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "flattened_sentiments_cat= np.hstack(df['st2_sentiment_llm_categorical'].values)\n",
        "\n",
        "# Count the occurrences of each value\n",
        "value_counts = pd.Series(flattened_sentiments_cat).value_counts()\n",
        "# Create a bar plot with smaller bars\n",
        "plt.bar(value_counts.index, value_counts.values, color='blue', alpha=0.7, width=0.3)\n",
        "plt.title('Sentiment Bar Plot')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([0.0, 0.5, 1.0])\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ukHZpK87esiJ"
      },
      "source": [
        "### 1.3 Create different Dataframes (Sentences & full Document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kas2z-8wsNbe",
        "outputId": "5a7333be-d438-40bd-eb24-c384451ef041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(678930, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>brands strategy sustainability agenda care bey...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>successfully reduced carbon footprint absolute...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>end consumer business returned levels reduced ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>decoupling human economic activity natural res...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>inspired beiersdorf ambitious sustainability a...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   internal                                           sentence  sentiment\n",
              "0         1  brands strategy sustainability agenda care bey...        1.0\n",
              "1         1  successfully reduced carbon footprint absolute...        1.0\n",
              "2         1  end consumer business returned levels reduced ...        0.0\n",
              "3         1  decoupling human economic activity natural res...        0.0\n",
              "4         1  inspired beiersdorf ambitious sustainability a...        1.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_sentence_df(data):\n",
        "\n",
        "    # Select relevant columns\n",
        "    data = data[['internal','sentence_tokens','st2_sentiment_llm_categorical']]\n",
        "\n",
        "    # Explode the tokens, so each sentence is a row\n",
        "    data = data.set_index(['internal']).apply(pd.Series.explode).reset_index()\n",
        "\n",
        "    # Rename the columns and change order\n",
        "    data.rename(columns={'sentence_tokens': 'sentence', 'st2_sentiment_llm_categorical': 'sentiment'}, inplace=True)\n",
        "    data = data[['internal', 'sentence', 'sentiment']]\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['sentence'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Create sentence data\n",
        "sentence_df = create_sentence_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sentence_df.shape)\n",
        "sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "vf-rmV_PesiK",
        "outputId": "9aa43b1b-bd42-490c-ead3-a9d0bffff230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11072, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>document</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>brands strategy sustainability agenda care bey...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>management facts deutsche telekom cr report th...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>sustainable future se sustainability report de...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>management employees profile attractive employ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>sustainability goes far beyond climate action ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   internal                                           document  sentiment\n",
              "0         1  brands strategy sustainability agenda care bey...        1.0\n",
              "1         1  management facts deutsche telekom cr report th...        1.0\n",
              "2         1  sustainable future se sustainability report de...        1.0\n",
              "3         1  management employees profile attractive employ...        1.0\n",
              "4         1  sustainability goes far beyond climate action ...        1.0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to create document data\n",
        "def create_document_df(data):\n",
        "\n",
        "    # Join tokens\n",
        "    data['document'] = data['sentence_tokens'].apply(' '.join)  # Convert tokens to strings\n",
        "    data['sentiment'] = data['st2_sentiment_llm_categorical'].apply(np.mean).apply(discretize_sentiment)\n",
        "\n",
        "    # Convert types\n",
        "    data['internal'] = data['internal'].astype(int)\n",
        "    data['sentence'] = data['document'].astype(str)\n",
        "    data['sentiment'] = data['sentiment'].astype(float)\n",
        "\n",
        "    # Return needed columns and discretized mean of the sentiment\n",
        "    return data[['internal', 'document', 'sentiment']]\n",
        "\n",
        "# Create sentence data\n",
        "document_df = create_document_df(df)\n",
        "\n",
        "# Display header and shape\n",
        "print(document_df.shape)\n",
        "document_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The subsets for the training should have equally distributed classes. In addition, external and internal documents should be represented.  \n",
        "One of these conditions needs to be more \"loose\", we decide class equality is more important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16075"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_df['sentiment'].value_counts().min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "4IEirqQJmfLm",
        "outputId": "0a1940c5-c50a-452b-948c-361714ed5d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(96450, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133546</th>\n",
              "      <td>1</td>\n",
              "      <td>flow acquisitions dividends uses cash flow acq...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228287</th>\n",
              "      <td>1</td>\n",
              "      <td>tour gave impression life physical disability ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50137</th>\n",
              "      <td>1</td>\n",
              "      <td>internal principles guidelines reported water ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80103</th>\n",
              "      <td>1</td>\n",
              "      <td>annual report management report structure busi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49248</th>\n",
              "      <td>1</td>\n",
              "      <td>business segment currently reviewing whether i...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        internal                                           sentence  sentiment\n",
              "133546         1  flow acquisitions dividends uses cash flow acq...        0.5\n",
              "228287         1  tour gave impression life physical disability ...        0.0\n",
              "50137          1  internal principles guidelines reported water ...        0.0\n",
              "80103          1  annual report management report structure busi...        0.0\n",
              "49248          1  business segment currently reviewing whether i...        0.5"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def balance_sentiment_and_internal_sentences(df):\n",
        "    # Get minimum number of observations across sentiment classes\n",
        "    min_internal_count = df['sentiment'].value_counts().min()\n",
        "    \n",
        "    # Get the minimum number of observations between internal == 0 and internal == 1\n",
        "    min_sentiment_count = min(df[df['internal'] == 0].shape[0], df[df['internal'] == 1].shape[0], min_internal_count)\n",
        "\n",
        "    # Create \"balanced\" dataframe\n",
        "    balanced_df = pd.concat([df[df['internal'] == i].sample(min_sentiment_count*3, random_state=1) for i in df['internal'].unique()])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# Sample the sentence dataframe\n",
        "sub_sentence_df = balance_sentiment_and_internal_sentences(sentence_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_sentence_df.shape)\n",
        "sub_sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal</th>\n",
              "      <th>document</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>1</td>\n",
              "      <td>ceo portrait corporate creating value global g...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>balance sheet date events combined nonfinancia...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "      <td>secure future expresses reason guides decision...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>1</td>\n",
              "      <td>foreword content decarbonizing business respon...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1</td>\n",
              "      <td>combined management report sucheta group glanc...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    internal                                           document  sentiment\n",
              "58         1  ceo portrait corporate creating value global g...        0.0\n",
              "88         1  balance sheet date events combined nonfinancia...        0.0\n",
              "43         1  secure future expresses reason guides decision...        0.0\n",
              "55         1  foreword content decarbonizing business respon...        0.0\n",
              "73         1  combined management report sucheta group glanc...        0.0"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample the document dataframe\n",
        "sub_document_df = balance_sentiment_and_internal_sentences(document_df)\n",
        "\n",
        "# Display header and shape\n",
        "print(sub_document_df.shape)\n",
        "sub_document_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence subset:\n",
            "1    48225\n",
            "0    48225\n",
            "Name: internal, dtype: int64\n",
            "0.0    46601\n",
            "0.5    46543\n",
            "1.0     3306\n",
            "Name: sentiment, dtype: int64\n",
            "\n",
            "\n",
            "Document subset:\n",
            "1    9\n",
            "0    9\n",
            "Name: internal, dtype: int64\n",
            "0.0    18\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Inspect sampling results\n",
        "print('Sentence subset:')\n",
        "print(sub_sentence_df['internal'].value_counts())\n",
        "print(sub_sentence_df['sentiment'].value_counts())\n",
        "print('\\n')\n",
        "print('Document subset:')\n",
        "print(sub_document_df['internal'].value_counts())\n",
        "print(sub_document_df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop uncessary column and reset index\n",
        "document_df = document_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sentence_df = sentence_df.drop(columns=['internal']).reset_index(drop=True)\n",
        "sub_sentence_df = sub_sentence_df.drop(columns=['internal']).reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o1UJ8F9FesiK"
      },
      "source": [
        "As a result, the models can be evaluated and trained with 2 approaches:  \n",
        "- A dataframe containing the full document and a discretized mean sentiment of all included sentences\n",
        "- A dataframe containing each sentence with the corresponding discretized sentiment  \n",
        "- Two sampled subset dataframes for moel evaluation\n",
        "\n",
        "\"Discretized\" corresponds to the labels 0.0 (negative), 0.5 (neutral) and 1.0 (positive)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr2iVzZBesiL"
      },
      "source": [
        "## 2. Model Finetuning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The evaluation for the model is based on the following conceptual approach:\n",
        "1. Select multiple pretrained (Huggingface) models, based on previous stages\n",
        "2. Train the selected models on a small subset of the full documents and the single sentences to keep the training time short\n",
        "3. Compare the training outcomes of the different models on the two subsets and select the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compute the comparison metrics\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    \n",
        "    # Use the appropriate metrics, since we don't have discrete classes but a continous score \n",
        "    mse = mean_squared_error(y_true=labels, y_pred=pred)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=pred)\n",
        "    r2 = r2_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fzglNdb0esiM",
        "outputId": "3cc02fbb-4a45-4320-c9b0-bb78d703c4c8"
      },
      "outputs": [],
      "source": [
        "# Load Tensorboard for training monitoring\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "D-2Tp63XesiM",
        "outputId": "05ed8c73-846e-44a1-e12d-4e5b5134484e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-298d8263fa9219d1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-298d8263fa9219d1\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6010;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Start Tensorboard to monitor training processes\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Finetune Model 1: *distilbert-base-uncased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kwjEdd_oesiL"
      },
      "source": [
        "As a first test, we use the lightweight \"distilbert-base-uncased\" model and fine-tune it on the full documents and the sentences, since the finetuned *\"nlptown/bert-base-multilingual-uncased-sentiment\"* demonstrated high alignment with the gold standard in stage 2.  \n",
        "Since BERT only accepts 512 input word tokens, the full documents are heavyily truncated.  \n",
        "\n",
        "🤗 page: https://huggingface.co/distilbert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWYx-J7esiL",
        "outputId": "8307f8d4-dfe9-4999-9aa5-83f9f32507be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n",
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'vocab_transform.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'classifier.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'pooler.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'classifier.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.attention.self.query.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define pretrained tokenizer and model\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1) # 1 label to get a continuous score between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the torch datasets to use data in PyTorch and override necessary methods\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6ziqUCesiL"
      },
      "source": [
        "#### Finetune *distilbert-base-uncased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_sentence_df[\"sentence\"])\n",
        "y = list(sub_sentence_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_sent = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_sent = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_sent = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LySMEgQbesiL"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset_distilbert_sent,\n",
        "    eval_dataset=val_dataset_distilbert_sent,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gkzspgEResiM",
        "outputId": "544b3439-c9c8-4b11-bfc4-574588c30ef6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6330 10:37 < 56:38, 1.57 it/s, Epoch 0.47/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1806' max='1809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1806/1809 01:28 < 00:00, 20.45 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *distilbert-base-uncased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with a 70%, 15% and 15% ratio (train, valid, test)\n",
        "X = list(sub_document_df[\"document\"])\n",
        "y = list(sub_document_df[\"sentiment\"])\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3) # Split 70% train data\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5) # Split the other 30% in 50% each to get the correct ratio\n",
        "\n",
        "# Tokenize the datasets\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Create the train, validation and test dataset as PyTorch datasets\n",
        "train_dataset_distilbert_doc = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset_distilbert_doc = Dataset(X_val_tokenized, y_val)\n",
        "test_dataset_distilbert_doc = Dataset(X_test_tokenized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "args_distilbert = TrainingArguments(\n",
        "    output_dir=\"./evaluation/distilbert_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Huggingface Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args_distilbert,\n",
        "    train_dataset=train_dataset_distilbert_doc,\n",
        "    eval_dataset=val_dataset_distilbert_doc,\n",
        "    compute_metrics=compute_metrics\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/distilbert_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Finetune Model 2: *roberta-base*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a second model for the comparison, we choose RoBERTa. It is a further development of BERT and should perform better.  \n",
        "\n",
        "This model benefits substantially from extended training duration, larger data batches, and an increase in dataset size. Its performance further increases by eliminating the next sentence prediction objective and integrating longer sequences during training.  \n",
        "Lastly, the model's optimization is boosted by dynamically altering the masking pattern applied to the training data.\n",
        "\n",
        "Reference: https://arxiv.org/pdf/1907.11692.pdf  \n",
        "🤗 page: https://huggingface.co/roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load default methods again, since a few are overwritten for destillbert\n",
        "from datasets import Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the tokenizer for RoBERTa\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenize_and_format_sentence(examples):\n",
        "\n",
        "    # Tokenize the text and map sentiment to label\n",
        "    tokenized_inputs = tokenizer(examples['sentence'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    # Return both the tokenized inputs and labels\n",
        "    return {**tokenized_inputs, 'labels': labels}\n",
        "\n",
        "def tokenize_and_format_document(examples):\n",
        "    # Same as above for documents\n",
        "    tokenized_inputs = tokenizer(examples['document'], truncation=True, padding='max_length')\n",
        "    labels = examples['sentiment']\n",
        "    \n",
        "    return {**tokenized_inputs, 'labels': labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the base RoBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad4ba252861f483aa74c9da29f1824ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67515 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a48eb7e031442869a2dd5331c27e689",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14467 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb2a5f673ab64a2b8148c30fbb23fb25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14468 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_sent = train_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "val_dataset_roberta_sent = val_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "test_dataset_roberta_sent = test_dataset.map(tokenize_and_format_sentence, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_sent.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_sent,\n",
        "    eval_dataset=val_dataset_roberta_sent\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6330 08:08 < 43:28, 2.04 it/s, Epoch 0.47/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1806' max='1809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1806/1809 01:08 < 00:00, 26.42 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *roberta-base* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train, validation and test split (70%, 15% and 15%)\n",
        "train_dataset, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_dataset, test_dataset = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_dataset)\n",
        "val_dataset = Dataset.from_pandas(val_dataset)\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "\n",
        "# Tokenizing the datasets\n",
        "train_dataset_roberta_doc = train_dataset.map(tokenize_and_format_document, batched=True)\n",
        "val_dataset_roberta_doc = val_dataset.map(tokenize_and_format_document, batched=True)\n",
        "test_dataset_roberta_doc = test_dataset.map(tokenize_and_format_document, batched=True)\n",
        "\n",
        "# Set the correct data format for PyTorch\n",
        "train_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset_roberta_doc.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare to train the model\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/roberta_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=1,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset_roberta_doc,\n",
        "    eval_dataset=val_dataset_roberta_doc\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train the model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/roberta_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Finetune Model 3: *xlnet-base-cased*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XLNet is a pretraining model for natural language processing tasks that combines the advantages of both autoregressive language models and denoising autoencoding models like BERT. \n",
        "Unlike BERT, XLNet mitigates dependency issues between masked positions and avoids a pretrain-finetune discrepancy by employing a generalized autoregressive method. \n",
        "This approach allows for learning bidirectional contexts by maximizing expected likelihood over all possible factorization orders. \n",
        "Furthermore, it integrates the strengths of Transformer-XL, a leading autoregressive model, into its pretraining procedure. \n",
        "Empirical evidence suggests that XLNet surpasses BERT in performance across a range of tasks including question answering, natural language inference, sentiment analysis, and document ranking.\n",
        "\n",
        "Reference: https://arxiv.org/abs/1906.08237  \n",
        "🤗 page: https://huggingface.co/xlnet-base-cased\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased')\n",
        "# Load the XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs\n",
        "    inputs = tokenizer(sentences, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors and resize to match input dimensions\n",
        "    labels = torch.tensor(labels).unsqueeze(1).float()\n",
        "\n",
        "    return inputs.input_ids, labels\n",
        "\n",
        "# Create torch Dataset and adjust methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on sentence subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_sentence_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_sentence_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['sentence'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['sentence'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['sentence'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_sent = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_sent = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_sent = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_sent,\n",
        "    eval_dataset=val_dataset_xlnet_sent,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1001' max='6330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1001/6330 17:11 < 1:31:40, 0.97 it/s, Epoch 0.47/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='395' max='6029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 395/6029 00:53 < 12:50, 7.32 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finetune *xlnet-base-cased* on document subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data with 70%, 15% and 15% \n",
        "train_df, temp_df = train_test_split(sub_document_df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(sub_document_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Get sentences and labels\n",
        "train_sentences = train_df['document'].tolist()\n",
        "train_labels = train_df['sentiment'].tolist()\n",
        "val_sentences = val_df['document'].tolist()\n",
        "val_labels = val_df['sentiment'].tolist()\n",
        "test_sentences = test_df['document'].tolist()\n",
        "test_labels = test_df['sentiment'].tolist()\n",
        "\n",
        "# Prepare inputs and labels\n",
        "train_input_ids, train_labels = prepare_data(train_sentences, train_labels)\n",
        "val_input_ids, val_labels = prepare_data(val_sentences, val_labels)\n",
        "test_input_ids, test_labels = prepare_data(test_sentences, test_labels)\n",
        "\n",
        "# Create sentence datasets\n",
        "train_dataset_xlnet_doc = SentimentDataset(train_input_ids, train_labels)\n",
        "val_dataset_xlnet_doc = SentimentDataset(val_input_ids, val_labels)\n",
        "test_dataset_xlnet_doc = SentimentDataset(test_input_ids, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/xlnet_documents\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=100,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_xlnet_doc,\n",
        "    eval_dataset=val_dataset_xlnet_doc,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "# Train pre-trained model\n",
        "trainer.train()\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/xlnet_documents\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Finetune Model 4: *flan-t5-base* (not working correctly)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "🤗 page: https://huggingface.co/google/flan-t5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Use correct Dataset class and adjust needed methods\n",
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels.float()\n",
        "        self.decoder_input_ids = torch.ones((len(labels),1), dtype=torch.long) # Initialize with start token\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        item['decoder_input_ids'] = self.decoder_input_ids[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def prepare_data(sentences, labels):\n",
        "    # Tokenize the inputs with added task-specific prefix (\"sentiment\")\n",
        "    inputs = tokenizer([\"sentiment: \" + sentence for sentence in sentences], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
        "\n",
        "    # Convert labels to tensors\n",
        "    labels = torch.tensor(labels.to_numpy())\n",
        "\n",
        "    dataset = SentimentDataset(inputs, labels)\n",
        "    return dataset\n",
        "\n",
        "sentence_data = sub_sentence_df['sentence']\n",
        "label_data = sub_sentence_df['sentiment']\n",
        "\n",
        "train_frac = 0.8\n",
        "train_size = int(train_frac * len(sentence_data))\n",
        "\n",
        "train_sentences = sentence_data[:train_size]\n",
        "train_labels = label_data[:train_size]\n",
        "\n",
        "val_sentences = sentence_data[train_size:]\n",
        "val_labels = label_data[train_size:]\n",
        "\n",
        "train_dataset = prepare_data(train_sentences, train_labels)\n",
        "val_dataset = prepare_data(val_sentences, val_labels)\n",
        "\n",
        "def compute_metrics_flan(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Reduce predictions to a single value per sequence (e.g., using mean)\n",
        "    predictions = predictions.mean(dim=-1)\n",
        "\n",
        "    mse = mean_squared_error(y_true=labels, y_pred=predictions)\n",
        "    mae = mean_absolute_error(y_true=labels, y_pred=predictions)\n",
        "    r2 = r2_score(y_true=labels, y_pred=predictions)\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"R2\": r2}\n",
        "\n",
        "class SentimentTrainer(Trainer):\n",
        "    def predict(self, test_dataset):\n",
        "        predictions, labels, _ = super().predict(test_dataset)\n",
        "        # convert predicted token ids to float values\n",
        "        predictions = [float(tokenizer.decode(pred)) for pred in predictions]\n",
        "        return predictions, labels\n",
        "    \n",
        "    # Adjust loss function to regression\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Reduce logits to a single value per sequence (e.g., using mean)\n",
        "        logits = logits.mean(dim=-1)\n",
        "\n",
        "        # Use MSE loss for regression\n",
        "        loss_fct = torch.nn.MSELoss()\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./evaluation/flant5_sentences\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    seed=0,\n",
        "    optim=\"adamw_torch\", # Use newer PyTorch optimizer\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=10,\n",
        "    fp16=True,\n",
        "    report_to='tensorboard')\n",
        "\n",
        "trainer = SentimentTrainer(\n",
        "    model=model,              \n",
        "    args=training_args, \n",
        "    compute_metrics=compute_metrics_flan,     \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Delete GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./models/flant5_sentences\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T5 models are normally used for text-to-text tasks. Therefore, fine-tuning T5 for a classification task with a continous prediction between 0 and 1 is a bit of a diversion. Still, above code works and the training can be started.  \n",
        "But the user-defined loss function does not work properly (it does not drop, but shows 0 throughout the training), and there is also uncertainty about the correct encodings.  \n",
        "\n",
        "Therefore, this model is not considered."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Evaluation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The finetuned models are evaluated based on MSE, MAE and R2. In addition, the test datasets are used to test the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1808' max='1809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1808/1809 02:09 < 00:00, 13.94 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load trained distilbert model\n",
        "model_distilbert_sent = BertForSequenceClassification.from_pretrained('./models/distilbert_sentences/', num_labels=1)\n",
        "# Define distilbert test trainer\n",
        "trainer_distilbert_sent = Trainer(model_distilbert_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_distilbert_sent = trainer_distilbert_sent.predict(test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1808' max='1809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1808/1809 02:06 < 00:00, 14.25 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load trained RoBERTa model\n",
        "model_roberta_sent = RobertaForSequenceClassification.from_pretrained('./models/roberta_sentences/', num_labels=1)\n",
        "# Define RoBERTa test trainer\n",
        "trainer_roberta_sent = Trainer(model_roberta_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_roberta_sent = trainer_roberta_sent.predict(test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6028' max='6029' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6028/6029 19:02 < 00:00, 5.27 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load trained xlnet model\n",
        "model_xlnet_sent = XLNetForSequenceClassification.from_pretrained('./models/xlnet_sentences/', num_labels=1)\n",
        "# Define xlnet test trainer\n",
        "trainer_xlnet_sent = Trainer(model_xlnet_sent)\n",
        "# Make predictions on the test subset\n",
        "pred_xlnet_sent = trainer_xlnet_sent.predict(test_dataset_xlnet_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_distilbert_sent.evaluate(eval_dataset=test_dataset_distilbert_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_roberta_sent.evaluate(eval_dataset=test_dataset_roberta_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_xlnet_sent.evaluate(eval_dataset=test_dataset_xlnet_sent)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Tensorboard to inspect the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kill potential Tensorboard process, so it don't block the port\n",
        "!pkill -f \"tensorboard\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start Tensorboard to monitor training process\n",
        "%tensorboard --logdir ./evaluation/ --port 6010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_dataset_distilbert_doc\n",
        "# test_dataset_roberta_doc\n",
        "# test_dataset_xlnet_doc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c_FFqFrresiO"
      },
      "source": [
        "## 4. Hyperparameter Tuning for selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYcomVCfesiP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Full Training of selected Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed up the full training, PEFT (https://github.com/huggingface/peft) is considered.  \n",
        "RoBERTa supports LoRa, Prefix Tuning, P-Tuning and Prompt Tuning: https://github.com/huggingface/peft#sequence-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation of fully trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sentiment Prediction with selected Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rK7BZAfyx_rY"
      },
      "source": [
        "## 8. Compare internal vs. external"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
